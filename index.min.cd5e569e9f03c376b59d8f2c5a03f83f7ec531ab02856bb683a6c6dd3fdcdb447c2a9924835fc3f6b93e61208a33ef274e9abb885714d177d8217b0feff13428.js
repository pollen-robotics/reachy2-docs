var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/help/help/",title:"Debug",description:"Learn how you can debug Reachy.",content:""}),e.add({id:1,href:"/advanced/overview/",title:"Overview",description:"A quick overview of Reachy.",content:""}),e.add({id:2,href:"/advanced/specifications/",title:"Specifications",description:"A quick overview of Reachy.",content:""}),e.add({id:3,href:"/advanced/overview/reachy2/",title:"Reachy 2",description:"Reachy 2 mobile robot.",content:`Reachy + mobile base is composed of two parts:
a full kit Reachy robot (i.e. with two arms, torso and a head), an omnidirectional mobile base For more info on what is included in the mobile base, check the mobile base specifications.
`}),e.add({id:4,href:"/advanced/safety/",title:"Safety first",description:"Safety measures to take when using Reachy and it smobile base.",content:""}),e.add({id:5,href:"/advanced/software/",title:"Reachy's software",description:"Description of Reachy's software architecture.",content:""}),e.add({id:6,href:"/advanced/services/",title:"Services",description:"Use systemd services with Reachy.",content:""}),e.add({id:7,href:"/advanced/specifications/general-specs/",title:"General specifications",description:"Reachy's full/starter kit general specifications: material used for pieces, power consumption, dimensions, weight.",content:`Construction: 3D printed MJF Painted - Flexible PU molded - Aluminium
Max Power consumption: 180W
Full Kit Dimensions: 670x450x200mm (670x1800x200mm with arms outstretched)
Starter Kit Dimensions: 670x380x200mm (670x1008x200mm with arms outstretched)
Weight: 6.2kg without metal fixation
`}),e.add({id:8,href:"/advanced/specifications/arm-specs/",title:"Arm specifications",description:"Reachy's 2023 arm specifications: material used for pieces, power consumption, dimensions, weight, payload, degrees of freedom.",content:`Construction: 3D printed MJF Painted- 3 axial needle roller bearings
Power consumption: 51W
Dimensions: 662x88x73mm
Weight repartition #Overall Arm: 1670g
Shoulder: 240g
Upper arm: 610g
Forearm: 590g
Gripper: 230g
Maximum payload: 500g
(this may vary depending on the holding and duration configuration)
Degrees of freedom #Reachy\u0026rsquo;s arm offers 7 degrees of movement + 1 for the gripper
Right arm Left arm Motor name Angle limits Motor ID Motor name Angle limits Motor ID shoulder_pitch -150, 90 10 shoulder_pitch -150, 90 20 shoulder_roll -180, 10 11 shoulder_roll -10, 180 21 arm_yaw -90, 90 12 arm_yaw -90, 90 22 elbow_pitch -125, 0 13 elbow_pitch -125, 0 23 forearm_yaw -100, 100 14 forearm_yaw -100, 100 24 wrist_pitch -45, 45 15 wrist_pitch -45, 45 25 wrist_roll -55, 35 16 wrist_roll -35, 55 26 gripper -50, 25 17 gripper -25, 50 27 Motors 3 Dynamixel MX-106T 1 Dynamixel MX-64AT 4 Dynamixel MX-28AT Fans #3 fans (shoulder, elbow and wrist)
`}),e.add({id:9,href:"/advanced/specifications/gripper-specs/",title:"Gripper specifications",description:"Reachy's 2023 gripper specifications: material used for pieces, power consumption, dimensions, weight.",content:`Animated by 1 Dynamixel MX-28AT.
Includes a micro load cell 0.78 Kg
Construction: 3D printed MJF Painted - Flexible PU molded
Power consumption: 5.3W
Dimensions: 117.3x84x51.4mm
Weight: 0.3Kg
`}),e.add({id:10,href:"/advanced/specifications/head-specs/",title:"Head specifications",description:"Reachy's 2023 head specifications: material used for pieces, power consumption, dimensions, weight, cameras, description of neck joint and antennas.",content:`Construction: 3D printed MJF Painted.
Power consumption: 15W.
Dimensions: 175x253x108mm.
Weight: 0.675Kg.
Reachy’s head features two motorized high quality wide angle cameras, to observe its environment as well as being able to focus on the task of manipulating. The head is animated by Orbita, a unique technology developed by Pollen Robotics’ R\u0026amp;D team. This ball joint actuator allows unpreceded dynamic and multi-directional movement. With animated antennas, Reachy can convey many emotions to his audience.
See the head in action in this video:
Cameras #Dual 1080p@30fps camera with motorized zoom (FOV 65° to 125°), associated with 2 optical lenses.
Orbita neck joint #Ball joint actuator that is composed of a parallel mechanism motorized by 3 brushless Maxon motors. The control of each motor is done with a magnetic absolute encoder included on the electronic board on top of Orbita.
Antennas #Antennas are animated by a Dynamixel motor and are removable.
A system of 3 magnets allow the attachment of the antennas to the rotation axis.
`}),e.add({id:11,href:"/advanced/specifications/torso-specs/",title:"Torso specifications",description:"Reachy's 2023 torso specifications: material used for pieces, dimensions, weight and description of each hardware installed in it (computer, microphone, TPU, speaker, amplifier, power supply).",content:`Construction: 3D printed MJF Painted - Aluminium
Power consumption: 36W
Dimensions: 300x350x150mm
Weight: 1.7Kg
Reachy\u0026rsquo;s torso area includes the following elements:
Computer #Powerful internal computer NUC intel i5 quad-core 1.6Ghz with 16Go DDR4 and 256Go SSD (NUC8v5PN)
Microphone #Seeed Studio - ReSpeaker Mic Array v2.0: Microphone array for NLU (ReSpeaker) and a 3.5mm jack audio output
TPU #Embedded TPU Google Coral G950-01456-01 for running ML models inference at high speed locally
Speaker #2x 12W - 4Ohm Tectonic TEBM36S12 Speakers allowing stereo sound.
Amplifier #Drocking PAM8620 12V audio amplifier
Power supply #Mean Well - GST220A12-R7B180W - output 12V 15 A (input 85~264VAC - 120~370VDC)
`}),e.add({id:12,href:"/advanced/specifications/orbita-specs/",title:"Orbita specifications",description:"Orbita spherical joint specifications: material used for pieces, power consumption, dimensions, weight, gearbox, degrees of freedom and limit angles.",content:`Specifications #Construction: Aluminium machined and SLS printed parts - Custom steel gears - metal bearings and axes.
Power consumption: 8W
Voltage: 12V
No-load speed: 25rpm
Max Continous torque: 1.7Nm
Gear reduction ratio: 4.2666
Diameter: 70mm height: 170mm Weight: 850g
Motor + Gearbox specifications #Power consumption: 8W
Voltage: 12V
No-load speed: 105 rpm
Max Continous torque: 0.4 Nm
Gear reduction ratio: 35:1
Diameter: 22mm
Height: 75mm
Motor\u0026rsquo;s full specification here
Degrees of freedom #Orbita has 3 degrees of freedom actuated by three motors described above.
They correspond to three rotation at the same point like Roll Pitch Yaw rotations.
Angle limits
Roll: -46° to 46°
Pitch: -46° to 46°
Yaw: 360° full rotation
`}),e.add({id:13,href:"/advanced/specifications/mobile-base-specs/",title:"Mobile Base specifications",description:"Reachy's mobile base specifications: material used for pieces, power consumption, dimensions, weight, description of sensors, wheels and battery.",content:`Specifications #Construction:
Cylinder shape Aluminium, MJF 3D printed plastic parts, Steel Dimension: 50*25cm
Weight: 25kg
Payload: 80kg
Sensors:
Hall Sensors and IMU on each wheel RP Lidar S2 (30m radius distance, 32k measurments/s, 0.12° angle resolution, resistance to sunlight…) Wheels:
3x Omnidirectional wheels 300W Max power No-load speed: 210 rpm Stall Torque: 13Nm - 13A Rated load, speed and current : 5Nm, 115rpm, 5A Battery OlenBox M:
24V, 35Ah 19.5 x 17.2 x 13.4cm, 6.5kg 5 years warranty Equipped with a BMS for safety Battery state indicator Emergency Stop: The emergency stop can be placed on the robot or in the users hands. The E-stop instantly shuts down the entire robot.
`}),e.add({id:14,href:"/advanced/safety/correct-use/",title:"Use Reachy properly",description:"Safety measures with Reachy to protect the user and prevent the robot from damaging. Following this measures will ensure the longetivity of the robot.",content:`Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programming it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
Your browser does not support the video element.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand as in the video above. It cannot be controlled with code, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You should hear a small noise coming from a motor in stiff mode, especially if you try to move it with your hands, it\u0026rsquo;s totally normal. Your browser does not support the video element.
Check out the Python SDK section on how to switch between the two modes.
🚨 What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, mind the obstacles that could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to use the motor\u0026rsquo;s switch in Reachy\u0026rsquo;s back to immediately turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
Good practices #Here is a non-exhaustive list of things to remember when you are using your Reachy, in order to make it last as long as possible.
Make sure that the robot is turned off and that the power supply is disconnected when you are not using it. Remember not to let the motors in stiff mode if you don\u0026rsquo;t plan to make them move. Even letting the arms on a table and in stiff mode for quite some time might damage them. Check that no obstacles will be on Reachy\u0026rsquo;s way when it will try to move. Sending commands to Reachy\u0026rsquo;s arms with an obstacle on the way will make the motors force as much as they can. Being in this kind of situation might happen but when this does, remember to turn off the motors immediately using the switch button in Reachy\u0026rsquo;s back. `}),e.add({id:15,href:"/advanced/safety/mobile-base/",title:"Use the mobile base properly",description:"Safety measures to follow with Reachy's mobile base.",content:`Basic mouvements #We recommend that you get a feel for the inertia of the robot by holding on to the metal pole and pushing and pulling it.
Block a wheel with your foot and try to gently tilt the robot.
Then use the controller to move around the robot as explained in Moving the mobile base
Your browser does not support the video element.
Common risks and advice #Even though the mobile base is programmed to move relatively slowly, it is important to try to avoid any potential collisions. The mobile base is designed to be used indoors on a flat surface.
💡 The arms and any grasped objects should ideally be in the vertical projection of the mobile base. The idea here is that the robot should always be able to rotate in place safely. Also, keeping the arms tugged in reduces the risk of tipping.
A low level collision avoidance safety always runs in the background, but it can only prevent collisions seen by the LIDAR. Read more about it in Anti-collision safety. A non exaustive list of cases where the safety can\u0026rsquo;t work:
Stairwells. There are no cliff sensors so the robot has no practical way of knowing it\u0026rsquo;s near downward stairs. A table. The LIDAR can see the legs but not the table top. A large clean bay window migh be invisible to the LIDAR. Small obstacles that fit below the LIDAR won\u0026rsquo;t be seen. Another risk is the robot tipping. Avoid rapid variations in acceleration. Also, we don\u0026rsquo;t recommend using the robot on a slope above 10°.
Battery management #We chose a high end battery for the mobile base. The Life4PO technology and the overal grade of the equipement (BMS, charger, monitoring system, certified UN 38.3, 5 years warranty), should make this one of the safest choices available on the market. However, the battery can hold a large amount of energy (832 Wh) and should always be treated carefully.
⚠️ Only use the dedicated charger to charge the battery
💡 When stocking the battery for long periods, aim for at least 60% charge
💡 Use the monitoring system (small screen on the mobile base) to recharge the battery before reaching 0% and relying on the BMS to shutdown the battery.
Dynamic capabilities #The wheel motors are very potent. In their default configuration, they are used at 20% of their maximum capabilities. You can, at your own risk, modify this limit in the configuration of the HAL.
`}),e.add({id:16,href:"/advanced/software/presentation/",title:"Overall presentation",description:"Presentation of the different components of Reachy's software and how they interact.",content:`Reachy\u0026rsquo;s software is composed of three main parts:
a HAL (Hardware Abstraction Layer) handling the communication with Reachy\u0026rsquo;s sensors i.e. the Dynamixel motors in the arms, fans, force sensors and Orbita actuator.
ROS packages: this is the core of the software. We are using ROS (Robotics Operating System), more precisely the ROS2 Humble distribution, and interact with the HAL via ros2 control. ROS packages are used to compute the kinematics for Reachy\u0026rsquo;s arms and Orbita, to get the camera feed and to manage the autofocus on Reachy\u0026rsquo;s motorised zooms.
Another ROS package is also used, along with gRPC, to create a server interacting with the different ROS nodes and services made for Reachy and allowing remote control on the robot without being physically connected to it.
gRPC client: the strength of using the gRPC framework is that we can have a remote control to the robot and create clients in any programming language (Python, C++, C#, \u0026hellip;). So knowing how to use ROS is not needed to work with Reachy.
Packages #The packages developed for Reachy 2023 are divided into two categories: the ROS packages and non-ROS packages.
ROS #(installed in ~/reachy_ws folder of Reachy\u0026rsquo;s computer)
The main package is reachy_2023. It contains multiple sub-packages:
reachy_description: publishes the robot\u0026rsquo;s URDF and control tag, needed by the kinematics package and by the different ROS simulation tools (rviz, gazebo, \u0026hellip;)
reachy_kdl_kinematics: computes the forward / inverse kinematics of Reachy\u0026rsquo;s arms and the forward / inverse kinematics of Orbita.
reachy_controllers: communicates with the HAL through ROS control hardware interface.
camera_controllers: communicates with the camera using v4l2 and zoom.
gripper_safe_controller: Smart gripper controller that automatically adjusts target position to avoid forcing.
reachy_msgs: specific ROS messages for Reachy
reachy_bringup: bringup launch file (can launch real, fake or gazebo reachy with or without RViz, etc.)
reachy_sdk_server: creates two gRPC servers, camera_server to get the camera\u0026rsquo;s images and control the motorised zooms and reachy_sdk_server for the joints, load sensors, fans and Orbita.
Mobile base #The following package is only needed if you have a Reachy with mobile base:
mobile_base_controller with the following sub-packages:
zuuu_hal: HAL dedicated to the mobile base zuuu_interfaces: custom ROS services for the mobile base mobile_base_sdk_server: creates a gRPC server to control the mobile base 💡 Zuuu is the internal name of the mobile base. It\u0026rsquo;s a french onomatopoeia that evokes swift mouvements :)
Non-ROS #(installed in ~/dev folder of Reachy\u0026rsquo;s computer)
The main library you will use:
reachy_sdk: SDK Python to control Reachy and develop applications Other dependencies for more specific use cases:
reachy_sdk_api: protobuf services and messages definition for the gRPC servers zoom_kurokesu: Python library to control Reachy\u0026rsquo;s motorized zooms Mobile base #The following package is only needed if you have a Reachy with mobile base:
mobile_base_sdk: SDK Python to control Reachy\u0026rsquo;s mobile base without necessarily having a Reachy robot connected. Controling the mobile base using reachy_sdk actually uses the mobile_base_sdk but hides it. gRPC clients #As explained, the gRPC clients permits the communication with the gRPC server through a network and without being physically connected on the robot. The gRPC clients can be installed on another machine and have few requisites, there is no need for the machine to have ROS installed on it.
gRPC clients can be in different programming languages. Currently, you can remotely control your robot using:
reachy_sdk: as described above, SDK Python to control Reachy\u0026rsquo;s arm, head, gripper. This is the library that we use when we want to develop an app on Reachy or test a new robot, mobile_base_sdk: SDK Python to control Reachy\u0026rsquo;s mobile base. It can work on the mobile base alone and with this, you don\u0026rsquo;t have to worry about whether or not Reachy\u0026rsquo;s motors are on or if Reachy\u0026rsquo;s main service is running. 💡 To learn more on the packages content and usage, please refer to README.md files of each directory.
👉 Want to get the latest software updates?Check how to do it here! Sum up #The diagram below sums up what has been described in this page.
`}),e.add({id:17,href:"/advanced/software/ros2-level/",title:"Working with ROS2 Humble",description:"Working at the ROS level of the robot. What are the different nodes available.",content:`Even if gRPC clients are available to control Reachy without knowing how to use ROS, you may want to work at the ROS level to implement new things for Reachy or use the tools provided by ROS. In this page, we will describe how to use the specfic ROS2 packages for Reachy.
Reachy runs natively on ROS2 Humble. ROS stands for Robotic Operating System, it offers a huge variety of compatible algorithms and hardware drivers.
The embedded NUC computer comes with ROS2 and Reachy specific packages already installed and running. They provide full access to Reachy. You can:
get the /joint_states and /dynamic_joint_states use Rviz to visualize your robot (either real or simulated) subscribe to various sensor topic (camera, force sensor, etc) publish position, torque, pid, etc commands using forward controller access client for IK/FK 💡 At this level, joints angles are handled in radians. NOTE: If you don\u0026rsquo;t know how to use ROS but still want to do it on Reachy, you should check the official ROS documentation, espcecially the tutorials showing examples and presenting the different key notions introduced by ROS.
What is runnning by default #If you have a Full kit or a Starter kit, reachy_sdk_server.service is enabled by default, meaninig that all Reachy ROS2 packages presented in the Overall presentation are automatically launched when you start the robot.
If you have a Reachy mobile, reachy_mobile_base.service is enabled along with reachy_sdk_server.service.
See section Using services for more information on the services.
You can check all ROS2 topics/services running on Reachy with:
ros2 topic listand
ros2 service listUsing launch files directly #The following presents what launch files can be launched, if you don\u0026rsquo;t whant to use the service. If you want to learn more about what is run by each launch file, check the README of the corresponding package.
Bringup #The launch file reachy.launch.py is the main entry point. It is reponsible for launching everything you need to use your Reachy. It can either connect to a real Reachy or simulate a fake one. You can run the sdk server or not, etc.
To connect to your robot and run everything needed to control it via ROS you can simply run:
ros2 launch reachy_bringup reachy.launch.pyIf you want to control it using the SDK (that is what is done by default by Reachy\u0026rsquo;s main service reachy_sdk_server.service):
ros2 launch reachy_bringup reachy.launch.py start_sdk_server:=trueSimilarly, if you want to control a fake Reachy using the SDK, you can run (we also launch RViz so you can see what\u0026rsquo;s going on):
ros2 launch reachy_bringup fake:=true start_sdk_server:=true start_rviz:=trueOther options are available and can be seen below:
ros2 launch reachy_bringup reachy.launch.py --show-argsArguments (pass arguments as '\u0026lt;name\u0026gt;:=\u0026lt;value\u0026gt;'):'start_rviz':Start RViz2 automatically with this launch file. Valid choices are: ['true', 'false'](default: 'false')'fake':Start on fake_reachy mode with this launch file. Valid choices are: ['true', 'false'](default: 'false')'gazebo':Start a fake_hardware with gazebo as simulation tool. Valid choices are: ['true', 'false'](default: 'false')'start_sdk_server':Start sdk_server along with reachy nodes with this launch file. Valid choices are: ['true', 'false'](default: 'false')This launch file actually runs many other launch files. If you want to have your custom launch file, the better way is probably to directly have a look at what\u0026rsquo;s inside.
Cameras nodes #Cameras nodes are available for full/starter kit only:
To run the camera view node ROS services:
ros2 run camera_controllers camera_publisherTo launch the camera zoom node ROS services:
ros2 run camera_controllers camera_zoom_serviceTo launch the camera focus node ROS services:
ros2 run camera_controllers camera_focusKinematics nodes #The Kinematics services are available to provide inverse and forward kinematics services for the arms, as well as inverse kinematics for the neck. They are launched automatically by the bringup launch file.
If you need to run them separately:
ros2 run reachy_kdl_kinematics reachy_kdl_kinematicsIt requires the robot_state_publisher to be running.
Mobile base #To launch the mobile base Hardware Abstraction Layer node:
ros2 launch zuuu_hal hal.launch.pyMany parameters on the mobile base like the maximum velocity can only be tuned at the ROS level. Check the mobile base\u0026rsquo;s HAL README to learn about what you can do with the mobile base at the ROS level.
SDK server nodes #A layer above ROS, you can interact with Reachy SDK API. The Python SDK offers a gRPC (Remote Procedure Call) interface to communicate with the server.
To communicate with Reachy through the SDK, you need to launch server nodes that handle gRPC services. The easiest way is to use the special flag start_sdk_server:=true in the bringup launch file. But if you want to run it independently:
To launch the node for the joints, fans and kinematics gRPC services:
ros2 run reachy_sdk_server reachy_sdk_serverTo launch the node for the cameras view and zoom gRPC services (full/starter kit only):
ros2 run reachy_sdk_server camera_serverNote: For the servers to work, the required ROS services must be already launched. The easiest way is via the bringup launch file.
To launch the node for the mobile base gRPC services (mobile kit only):
ros2 launch mobile_base_sdk_server mobile_base_sdk_server.launch.py`}),e.add({id:18,href:"/advanced/software/configuration-file/",title:"Reachy's configuration file",description:"Reachy's configuration file is used to indicate which Reachy's configuration your robot has and whether a mobile base is connected to the robot or not.",content:`We created a custom yaml file (~/.reachy.yaml) to indicate which Reachy\u0026rsquo;s configuration your robot has and whether a mobile base is connected to the robot or not. Having this file is useful to start only the necessary code required by the Reachy version you are using.
This file is read when Reachy\u0026rsquo;s main services are launched at boot or by the bringup launch file.
The configuration file has multiple entries:
model: model of your Reachy (if it is a full kit, a starter kit, \u0026hellip;). When reachy_sdk_server.service starts, it will look at this entry to choose what code it has to run depending on the model of the robot. zuuu_model: is at None if no mobile base is attached with the robot, else the mobile base version is indicated (current mobile base version is 1.2). When reachy_mobile_base.service starts, if zuuu_model is not None, the mobile base code is launched. neck_zero_hardware: hardware position of the three disks. You should not need to change those values unless you changed Orbita. fan_trigger_temperature: temperature used to determine whether or not Reachy\u0026rsquo;s fans need to be turned on to cool the motors off. The default value is 45°C. Typically, ~/.reachy.yaml looks like this:
generation: 2023model: full_kitzuuu_version: 1.2neck_orbita_zero:top: 0.0middle: 0.0bottom: 0.0fan_trigger_temperature: 45camera_parameters:left:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0right:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0You can find a template here.
`}),e.add({id:19,href:"/advanced/services/available/",title:"Available system services",description:"Core services running on Reachy.",content:`System services are available on the robot to automatically launch at boot the most commonly used features of the robot. It is useful when you just want to use our Python SDK without having to worry about running by hand Reachy\u0026rsquo;s core ROS code. Nevertheless, you may want to use Reachy differently and deactivate them.
We use system.d to handle the services. If you are not familiar with this system, you should refer to the official documentation.
💡 The services are in user mode and stored in ~/.config/systemd/user.
Services available #reachy_sdk_server.service #For each Reachy\u0026rsquo;s configuration except for the Arm kit (i.e. Full, Starter and Mobile kit), the service reachy_sdk_server.service is available and enabled by default.
You can see how the service is defined on reachy_sdk_server repository but basically what this service does is executing a bash file which itself executes the ROS command:
ros2 launch reachy_bringup reachy.launch.py start_sdk_server:=trueThe bringup launch file will start each useful Reachy\u0026rsquo;s ROS node like a node to handle the joints, one for the kinematics, another for the cameras (if Reachy\u0026rsquo;s configuration has a head), \u0026hellip;
For the complete list of the ROS nodes launched by the service, check reachy.launch.py file.
reachy_mobile_base.service #If your Reachy is equipped with a mobile base, the service reachy_mobile_base.service is also available and enabled by default. Having separate services for Reachy and the mobile base allows to work separately with the mobile base or Reachy when you have a Reachy Mobile.
As reachy_sdk_server.service, reachy_mobile_base.service is defined in the mobile_base_sdk_server repository. The service executes a bash file which itself executes the ROS command:
ros2 launch mobile_base_sdk_server run_mobile_base_sdk_server_and_hal.launch.pyif a mobile base version is specified in Reachy\u0026rsquo;s configuration file.
The launch file launched will start the ROS nodes for the HAL of the mobile base and the node to start the gRPC SDK server to use the mobile base Python SDK.
For the complete list of the ROS nodes launched by the service, check run_mobile_base_sdk_server_and_hal.launch.py.
reachy_dashboard.service #The reachy_dashboard.service is also available and enabled by default on each Reachy. This service makes sure that the dashboard is started when the robot boots and that you can check its IP address on the LCD screen installed in its back.
What if I don\u0026rsquo;t want to use services #If you don\u0026rsquo;t want to use the default services, you can simply disable them so that they won\u0026rsquo;t start when booting the robot and launch Reachy\u0026rsquo;s ROS launch files by hand.
`}),e.add({id:20,href:"/advanced/services/manage-services/",title:"Manage Reachy's services",description:"Manage Reachy's core services.",content:`Use the dashboard! #Each Reachy\u0026rsquo;s service appear in the services page of the dashboard. A card is created for each service with three buttons: restart (to restart the service), stop (to stop it) and show logs (to have acces to the status of the service and check what is happening, useful for debug). Using the dashboard is the easiest way to manage Reachy\u0026rsquo;s services.
💡 A card will be created for one of Reachy\u0026rsquo;s services only if the service is enabled.
Manage the services by hand #It is of course possible to manage the services using CLI. The following commands are taken from systemd documentation. For more details, don\u0026rsquo;t hesitate to check the documentation directly.
Start, restart or stop a service #Eachy Reachy\u0026rsquo;s services can be started, stopped or restarted by hand. It can be useful for situations where for example you turned Reachy\u0026rsquo;s computer on but forgot to turn on its motors. By restarting reachy_sdk_server.service, you would not have to reboot Reachy\u0026rsquo;s computer.
To start a specific service like reachy_sdk_server.service, type the following command in a terminal:
systemctl --user start reachy_sdk_server.serviceSimilarly, you can stop or restart a specific service by replacing the start keyword by either stop or restart. For example, to restart reachy_sdk_server.service, the command is:
systemctl --user restart reachy_sdk_server.serviceNote: if you stop a service, it will start again automatically at the next boot of Reachy\u0026rsquo;s computer. If you would prefer to always have the service stopped, you will have to disable it.
Get a service status #Having a service\u0026rsquo;s status can be really useful for debugging. With it you can know whether the service is active or not and especially, you can have access to the latest logs of the service. For example if you can\u0026rsquo;t connect to your Reachy or the mobile base with the Python SDK, there is probably a message in the service explaining why the code has crashed.
To get the status of a service like reachy_sdk_server.service, use
systemctl --user status reachy_sdk_server.serviceEnable or disable a service #There are situations when you would prefer to disable a service completely so that it is never started when Reachy\u0026rsquo;s computer is booting. It might be for example because you would prefer to start Reachy\u0026rsquo;s ROS code by hand to have a finer control on it.
If that is the case, you can disable a service like reachy_sdk_server.service with
systemctl --user disable reachy_sdk_server.serviceAt any time, if you prefer to work with the service again, you can enable it.
systemctl --user enable reachy_sdk_server.service`}),e.add({id:21,href:"/vr/getting-started/check-robot/",title:"Check robot is ready",description:`Little checks before start #When starting the robot, the services required for teleoperation are automatically launched.
SR camera must be unplugged #Make sure the SR camera is unplugged: it could cause troubles to launch the teleop cameras service.
Have you done anything since the last boot? #In the following cases:
you have just unplugged the SR camera, without rebooting the robot you have used the Python SDK during your session with the robot Then disconnect all running clients (if you used the Python SDK), and restart the webrtc service from the dashboard.`,content:`Little checks before start #When starting the robot, the services required for teleoperation are automatically launched.
SR camera must be unplugged #Make sure the SR camera is unplugged: it could cause troubles to launch the teleop cameras service.
Have you done anything since the last boot? #In the following cases:
you have just unplugged the SR camera, without rebooting the robot you have used the Python SDK during your session with the robot Then disconnect all running clients (if you used the Python SDK), and restart the webrtc service from the dashboard.
A reboot of the robot will also work.
`}),e.add({id:22,href:"/vr/getting-started/connect/",title:"Connect to Reachy 2",description:`Launch the app #Once everything is installed, you can launch the application.
First connect your headset to your computer and make sure it is ready for use.
Meta Quest headset must be used with the link.
Then run the Reachy2Teleoperation.exe file from the previously unzipped folder to start the application.
Find Reachy IP address #If you haven\u0026rsquo;t unplugged it, the LCD screen connected in Reachy\u0026rsquo;s back should be diplaying its IP address.`,content:`Launch the app #Once everything is installed, you can launch the application.
First connect your headset to your computer and make sure it is ready for use.
Meta Quest headset must be used with the link.
Then run the Reachy2Teleoperation.exe file from the previously unzipped folder to start the application.
Find Reachy IP address #If you haven\u0026rsquo;t unplugged it, the LCD screen connected in Reachy\u0026rsquo;s back should be diplaying its IP address.
If the LCD screen is not working or is unplugged, check out the page Find my IP section to learn other ways to get the IP address.
Connect to the robot #Create a new robot entry in the menu with the IP address you previously found.
Once the robot is created, select it and click on \u0026ldquo;Connect\u0026rdquo;.
You should then arrive in the transition room of the application.
A message to allow the network access to the app may pop up, in this case allow access:
Make sure the connection is fine by checking the information displayed at the top of the mirror.
You must see:
a green text telling you \u0026ldquo;Connected to Reachy\u0026rdquo; the view of the robot displayed in miniature a good network connection `}),e.add({id:23,href:"/vr/getting-started/installation/",title:"Installation",description:`⬇️ Download the latest version of the app On the Windows computer #1. Check VR device installation #Make sure that your VR device is properly installed and running (please refer to your device documentation).
2. Download application #Download the zip archive from our github repo, and unzip it.
Reachy 2 is already fully compatible with the teleoperation application. You have nothing to install on the robot.`,content:" ⬇️ Download the latest version of the app On the Windows computer #\r1. Check VR device installation #\rMake sure that your VR device is properly installed and running (please refer to your device documentation).\n2. Download application #\rDownload the zip archive from our github repo, and unzip it.\nReachy 2 is already fully compatible with the teleoperation application. You have nothing to install on the robot.\n👉 No standalone application is available yet for Reachy 2 teleoperation. 3. Install GStreamer #\rThe project relies on GStreamer.\nPlease install the Windows Runtime.\nChoose the complete installation: Add C:\\gstreamer\\1.0\\msvc_x86_64\\bin to your PATH environment variable.\nTo do so:\nAccess the Edit the system environment variables control panel: Open Environment Variables\u0026hellip;: Select the Path variable and click Edit\u0026hellip;: Click New and add C:\\gstreamer\\1.0\\msvc_x86_64\\bin to the list: Also check you have GSTREAMER_1_0_ROOT_MSVC_X86_64 in your System variables, value being C:\\gstreamer\\1.0/msvc_x86_64\\: Reboot your computer after the installation.\n4. Configure the firewall #\r5. Choose your headset refresh rate (optional) #\rIf you have a Meta Quest headet, we advise you to set the refresh rate at 120 Hz.\nTo do so, use the desktop Meta app (the one appearing on your computer when your headset is connected on your computer and the link activated).\nIn the devices tab, select your headset, and modify the graphics preferences in the advanced section.\n"}),e.add({id:24,href:"/vr/getting-started/setup/",title:"Setup your teleop session",description:`Audio and microphone setup #To have a better experience within the VR, configure the audio of your headset from your headset settings.
You should be able to speak through the robot and hear from it when you are in the transition room.
Check both audio input and output are on, and set them to a correct value.
On the Meta Quest 2 headset, we use the following parameters:
audio input: 100% audio ouput: 65% Motion sickness options #Once in the transition room, you have options you can configure to help you avoid motion sickness.`,content:`Audio and microphone setup #To have a better experience within the VR, configure the audio of your headset from your headset settings.
You should be able to speak through the robot and hear from it when you are in the transition room.
Check both audio input and output are on, and set them to a correct value.
On the Meta Quest 2 headset, we use the following parameters:
audio input: 100% audio ouput: 65% Motion sickness options #Once in the transition room, you have options you can configure to help you avoid motion sickness.
On the left of the mirror, open the Settings tab, and configure the motion sickness options before starting teleoperating the robot.
`}),e.add({id:25,href:"/vr/getting-started/",title:"VR Installation",description:"",content:""}),e.add({id:26,href:"/docs/simulation/simulation-installation/",title:"Simulation installation",description:"Simulation installation process.",content:`If you want to try movements on the robot without using the real robot, you can install a simulated Reachy 2 on your computer, and run it the same way the real robot is run.
Clone the sources of our docker, and pull the sources:
git clone git@github.com:pollen-robotics/docker_reachy2_core.git cd docker_reachy2_core ./pull_sources.sh beta Then download the configuration files:
git clone git@github.com:pollen-robotics/reachy_config_example.gitcp -r reachy_config_example/.reachy_config ~/In your docker_reachy2_core folder, compose a container with:
docker compose -f dev.yaml up -d coreThis can take a few minutes to compose.
Build:
cbuildsIn a first terminal, launch the robot server:
# terminal 1docker exec -it core bashros2 launch reachy_bringup reachy.launch.py fake:=true start_sdk_server:=true start_rviz:=trueKeep this terminal open, and in a second terminal:
# terminal 2docker exec -it core bashpython3 ../dev/reachy2-sdk/src/example/test_goto.pyIf you have the Python SDK installed on your computer, you can launch the example outside the container.
`}),e.add({id:27,href:"/docs/getting-started/hello-world/",title:"Hello World",description:"First robot use.",content:`1. Check services are running #All elements of the robots should have started automatically.
Check this is the case on the dashboard
2 services must be launched:
reachy2-core reachy2-webrtc Click on Logs for both services to check they have correctly started.
You should see content appearing under the services tab:
If you see any error, click on Restart to restart them.
2. Try sending commands #(Temporary checkup)
To check everything is working fine, you can use the examples of the Python SDK.
Clone reachy2-sdk #Clone reachy2-sdk repository from Github on your computer.
Try the jupyter notebook examples #Then go to reachy2-sdk/src/examples/, and try the two first jupyter notebooks:
1_getting_started 2_moves_introduction Check you manage to connect, to get data from the robot and to make it move.
We do not test the cameras from the Python SDK so far, because they can be accessed only by one service at the same time, and the webrtc service is already running by default.
`}),e.add({id:28,href:"/docs/getting-started/turn-on/",title:"Start your robot",description:"How to switch on your robot.",content:`Power up your robot #To start your robot:
Press the mobile base button (next to the mobile base\u0026rsquo;s LCD screen). The mobile base\u0026rsquo;s screen should turn on, indicating the current state of the battery (remaining battery percentage, current flow, etc).
Automatic calibration process
Put the robot in a environment with no obstacle, and make sure its arms or grippers are not touching the tripod.
👉 The robot is going to slightly move during the calibration. Do not touch the robot during the calibration, and make sure the arms will not meet any obstacle during their movements. Turn anti-clockwise the emergency stop button to raise it. The automatic calibration process will start.
Do not move the robot until the computer is ready for use.
Your browser does not support the video element.
Automatic calibration processTurn on the robot\u0026rsquo;s computer: plug the green connector to the computer. The computer should automatically turn on.
if the computer was already plugged, use the (a) button to turn it on. We advise to unplug the computer after each use for power saving, because the USB ports are still consuming current when the computer is off.
Your browser does not support the video element.
Full turn on process in video`}),e.add({id:29,href:"/docs/getting-started/turn-off/",title:"Stop your robot",description:"How to switch off your robot.",content:`Power off your robot #Power off your robot in the exact opposite order you turned it on!
To stop your robot:
From the dashboard, click on the Power Off button in the footer. Press the emergency stop button. Press the mobile base button. Wait for the led of the computer to turn off, then unplug the green port from the robot\u0026rsquo;s computer. Understanding the power buttons and battery life good practices #The mobile base uses the 24V battery to power the wheels directly. DC-DC converters are used to generate 5V (emergency button power, USB HUB power and relay logic) and 12V for the upper body. The 5V converter draws almost 100mA when idle and is necessary for the emergency button logic.
The emergency button and the mobile base button both need to be ON to turn on the power relay that shares the 24V with the rest of the robot. However, the mobile base button is the only one that, when turned OFF, shuts down the 5V converter.
⚠️ WARNING! ⚠️ When turning off the robot, always turn off the mobile base button to minimize the idle current consumption. If you turn off the robot with the emergency button and didn\u0026rsquo;t press the mobile base button before storing your robot, the battery will deplate faster.
💡 Even with the mobile base button OFF, the battery screen will be powered (low consumption at around ~1mA). If you plan to store the robot for more than a month, we recommend unplugging one of the wires of the battery (like when you received the robot).
Configuration Storage time before depleting a full battery Mobile base button ON, emergency button OFF A few days Mobile base button OFF A few months Unplugging the battery A few years `}),e.add({id:30,href:"/docs/getting-started/network/",title:"Connect your robot to the network",description:"How to connect your robot to the network.",content:` On the first connection, connect Reachy 2 to your network using an ethernet cable. You will then be able to choose another network using the dashboard.
Hard-wired connection #Use an ethernet cable to connect your robot to the network.
The ethernet plug is available at position (b) on Reachy’s hardware interface.
The computer inside Reachy is configured to use DHCP. It should thus be directly accessible on your network.
To easily find the IP address of the robot, read the little LCD screen plugged in the back of the robot. Wait for the IP address to appear, it may take a few minutes.
Every 10 seconds, the screen switches between WiFi and Ethernet information.
WiFi #After your first connection with an ethernet connection, simply use the dashboard to connect Reachy to WiFi.
If you cannot use an ethernet connection for your first connection: How to connect to WiFi without using the dashboard?
`}),e.add({id:31,href:"/docs/getting-started/dashboard/",title:"Connect to the dashboard",description:`The dashboard is here to give you an overview of the robot\u0026rsquo;s state (what services are running, is there an error on a motor,\u0026hellip;) and give you the possibility to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
1. Find Reachy 2\u0026rsquo;s IP address #After you connected the robot to the network, it should have an IP address.`,content:`The dashboard is here to give you an overview of the robot\u0026rsquo;s state (what services are running, is there an error on a motor,\u0026hellip;) and give you the possibility to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
1. Find Reachy 2\u0026rsquo;s IP address #After you connected the robot to the network, it should have an IP address. You can find it on the LCD screen if you haven\u0026rsquo;t unplugged it yet.
In case the screen does not display the IP address, follow the instructions of Find Reachy 2\u0026rsquo;s IP.
Note the LCD screen will not work if you plug it after having turned on the computer.
2. Connect from the navigator #From your computer, on the same network, open a navigator and go to:
http://\u0026lt;IP.address\u0026gt;:8000/
For example, if the screen indicates 192.168.1.42, connect to http://192.168.1.42:8000/
You should arrive on a services page:
`}),e.add({id:32,href:"/docs/advanced/calibrate-cameras/",title:"Calibrate teleop cameras",description:"How to calibrate the stereovision for the teleop cameras",content:`0. Dependencies #You will need to install Pollen\u0026rsquo;s multical fork. Follow instructions here.
1. Charuco calibration board #If you don\u0026rsquo;t have one, generate a charuco board with the following command:
\$ python3 generate_board.pyPrint it on a A4 paper and place it on a flat surface (we use a wooden board).
Mesure as accurately as possible the size of the squares and the size of the markers and edit the example_boards/pollen_charuco.yaml file in the previously cloned multical repo to report the values you measured (must be in meters).
2. Get some images #Run:
\$ python3 acquire.py --config CONFIG_??(CONFIG_?? is the name of the config file you want to use, it must be in pollen_vision/config_files/. Dont set the --config argument to see available config files)
Press return to save a pair of images in ./calib_images/ (by default, use --imagesPath to change this).
Try to cover a maximum of the field of view, with the board in a variety of orientations. If the coverage is good, about 30 images is sufficient. Also, make sure that most of the board is visible by all the cameras for all the saved images pairs.
Below is an example of good coverage: 3. Run multical #\$ cd \u0026lt;...\u0026gt;/multical\$ multical calibrate --image_path \u0026lt;absolute_path_to_calib_images_dir\u0026gt; --boards example_boards/pollen_charuco.yaml --isFisheye \u0026lt;True/False\u0026gt;(For some reason, \u0026ndash;image_path must be an absolute path, relative paths don\u0026rsquo;t work)
/!\\ Don\u0026rsquo;t forget to set --isFisheye to True if you are using fisheye lenses /!\\
It will write a calibration.json file in \u0026lt;path_to_calib_images_dir\u0026gt;.
4. Flash the calibration to the EEPROM #Run:
\$ python3 flash.py --config CONFIG_?? --calib_json_file \u0026lt;path to calibration.json\u0026gt;A backup file with the current calibration settings stored on the device will be produced in case you need to revert back.
If needed, run:
\$ python3 restore_calibration_backup.py --calib_file CALIBRATION_BACKUP_\u0026lt;...\u0026gt;.json 5. Check the calibration #Run:
\$ python3 check_epilines.py --config CONFIG_??And show the aruco board to the cameras.
An AVG SLOPE SCORE below 0.1% is OK.
Ideally it could be under 0.05%.
The lower, the better.
`}),e.add({id:33,href:"/docs/getting-started/wifi/",title:"Connect your robot to the WiFi",description:"How to connect your robot to the WiFi without using the dashboard.",content:`WiFi #On your first connection to a network, the simpliest is to connect your robot with an ethernet cable.
If you cannot do this:
Use the appropriate cable and connect your computer directly to Reachy 2\u0026rsquo;s computer. The cable has to be plugged in port (b) of Reachy 2\u0026rsquo;s hardware interface.
We use tiofor the serial connection. If you haven\u0026rsquo;t installed it yet on your computer: apt install tio
👉 Make sure dialout is in your groups, otherwise add it to your groups. To check it: \u003e\u003e\u003e groups If it doesn't appear in the list, add it with: \u003e\u003e\u003e sudo usermod -aG dialout \$USER Then reboot your computer for the new group to be effective. Then, in a terminal on your computer, get access to the robot with:
tio /dev/ttyUSB0Note that the connection could be on another USB port. Check all ports with ls /dev/ttyUSB*
👉 Login: bedrock Password: root Manually connect the robot to a WiFi with:
nmcli device wifi connect \u0026lt;wifi.name\u0026gt; password \u0026lt;your.password\u0026gt;For example, with the wifi POLLEN-WIFI, with password superstrongpassword:
nmcli device wifi connect POLLEN-WIFI password superstrongpassword
\u003c Back to network connection `}),e.add({id:34,href:"/docs/advanced/access-computer/",title:"Access Reachy 2 computer",description:"How to connect to the robot's embedded computer",content:`There are several ways to connect to your robot.
SSH connection #Using the robot\u0026rsquo;s IP address (check Find Reachy 2\u0026rsquo;s IP if you don\u0026rsquo;t know it), you can directly connect via ssh to Reachy 2\u0026rsquo;s computer:
ssh bedrock@\u0026lt;Reachy.2.IP.address\u0026gt;For example, with robot\u0026rsquo;s IP being 192.168.1.42:
ssh bedrock@192.168.1.42👉 Password: root Hard-wired connection #Use the appropriate cable and connect your computer directly to Reachy 2\u0026rsquo;s computer. The cable has to be plugged in port (b) of Reachy 2\u0026rsquo;s hardware interface.
We use tiofor the serial connection. If you haven\u0026rsquo;t installed it yet on your computer: apt install tio
👉 Make sure dialout is in your groups, otherwise add it to your groups. To check it: \u003e\u003e\u003e groups If it doesn't appear in the list, add it with: \u003e\u003e\u003e sudo usermod -aG dialout \$USER Then reboot your computer for the new group to be effective. Once connected, open a terminal on your computer and run:
tio /dev/ttyUSB0Note that depending on the elements you connected to the robot, the port could be something else than ttyUSB0. Check other available serial ports with ls /dev/ttyUSB*
👉 Login: bedrock Password: root You are then connected to Reachy 2 computer!
Avahi connection #Find the serial number of your robot on its back, connect your computer on the same network as your robot, open a terminal and type:
ping \u0026lt;robot.serial.number\u0026gt;.localFor example, if the serial number is reachy2-beta1:
ping \u0026lt;reachy2-beta1\u0026gt;.local`}),e.add({id:35,href:"/docs/getting-started/unpack/",title:"Unpack Reachy 2",description:"Unpack your robot to start with Reachy 2.",content:`Your robot is already assembled! #Simply unpack your robot, everything is already assembled and plugged.
Screw the robot antennas #Plug the WiFi antennas #Plug the antennas on the robot computer. Make sure to place them correctly so that the robot\u0026rsquo;s arms cannot touch them:
Plug the emergency stop button #To plug the emergency state button, you will find a little black connector on the mobile base. Simply connect the button cable to it.
Adjust robot size #Reachy 2 is mounted on its mobile base with a tripod for stability.
This tripod is adjustable in height: choose a suitable height before starting using the robot.
👉 Be careful, Reachy 2 is quite heavy. Ask for help to adjust robot size. To do so, maintain the mobile base and ask for someone to maintain the robot\u0026rsquo;s torso. Then unscrew all pods (do not unscrew them too much!), and raise the robot\u0026rsquo;s torso.
The button on the cranks are here to modify their positions without unscrewing them.
`}),e.add({id:36,href:"/vr/introduction/",title:"VR Introduction",description:"Get quickly introduced to VR teleoperation",content:""}),e.add({id:37,href:"/vr/use-teleop/start/",title:"Teleoperate Reachy",description:"Start and stop Reachy teleoperation using the VR app",content:` 👉🏾 Before starting teleoperating Reachy, please make sure you read the Best Practice In brief #👉 The button names used below are for the Meta Quest headsets. Please refer to the Controllers Input page to get the corresponding names for your device. Start teleoperating Reachy #Make sure the robot is turned on, connected to the network and that all the robot\u0026rsquo;s services are running before launching the teleoperation application.
Select the robot you want to teleoperate (or create a new one), and click on \u0026ldquo;Connect\u0026rdquo;.
Once in the mirror room, you can configure various settings. Take time to tune the motion sickness effects you want to use in the settings menu. When you are ready to start, press \u0026ldquo;Ready\u0026rdquo;, then hold (A).
Look straight ahead, with your body in the same orientation as your head while pressing A to start the teleoperation. The initial head position is used to determine the coordinate system giving your VR controllers position.
👉 Warning: you must not move your body anymore after this step. The position of your VR controllers to master the robot arms are calculated depending on the position you had while pressing A. 🚨 Important: even if Reachy is bio-inspired, it cannot reproduce exactly all your movements. There are positions that cannot be reached by the robot. Please avoid unusual movements and do not persist in trying to reach a position if you see that the robot is stuck before it. (NEW) You first have the control of the head and the mobile base, but not of the arms. Take a few seconds to check the robot surroundings and go to an appropriate place before starting the full teleoperation. When the environment is safe, press A to get the full control. You can also go back to the mirror room pressing the related button with your laser beam.
Come back any time to mirror room by holding A. Teleoperation of the robot is automatically paused if the headset is removed.
👉 Please stop teleoperation before removing your headset (go back to mirror room or quit the app). If you do not, Reachy will continue following your controllers and headset orientation during a few seconds, and this can cause damages to the robot. Stop teleoperation #Come back to the mirror room to pause the teleoperation by holding A at any time during teleoperation.
Leave the app by clicking \u0026ldquo;Quit\u0026rdquo; icons in the mirror room and connection menu.
The motors are automatically turned into compliant mode when quitting the mirror room. Please make sure the arms are close enough to the lowest position they can reach when coming back to the menu to avoid them falling or hitting something.
Step-by-step starting #Make sure that your VR equipement is up and running. Please refer to your device documentation.
Make sure the robot is turned on, connected to the network and that all the robot services are running. By default, if you haven\u0026rsquo;t modified anything, all services should be automatically launched on start of the full/starter kit robots.
Launch the application TeleoperateReachy.exe file if you are using a VR device connected to a Windows computer. For Oculus Quest users, start the app from within the headset if you have installed the .apk.
Equip yourself with your headset, make sure you can see both controllers and that the scene around you is moving correctly in accordance with your head movements.
Choose the robot you want to connect to: you can select a robot with its IP address, or add a new one to the list of available robots.
Press Connect to initiate the communication with the robot. You should be now in the mirror room, and see yourself controlling a virtual reachy. The actual robot is not in control at that time but the live camera stream is displayed at the top right of the mirror. The info, help and settings menus are available here (they are documented in the next section). Please get familiar with the robot controls and features (emotion, grasping lock). When you are ready, face the mirror completely and click on \u0026ldquo;Ready\u0026rdquo;. The position of the actual robot appears in a semi-transparent green color. This may be useful when you\u0026rsquo;ve left the robot in a certain position that you would like to keep when entering the teleoperation. Hold (A) to start the teleoperation. (NEW) You first have the control of the head and the mobile base, but not of the arms. Take a few seconds to check the robot surroundings and go to an appropriate place before starting the full teleoperation. When the environment is safe, press A to get the full control. You can also go back to the mirror room pressing the related button with your laser beam.
A 3 seconds timer appears while you enter the teleoperation. The motors speeds are reduced during this time to avoid sudden movements of the robot. Full speed is reached at the end of this countdown.
👉 Warning: you don't want to move your torso and body anymore after this step. Only your head and arms. The position of your VR controllers to master the robot arms are calculated depending on the position you had while pressing A. Come back any time to menu by pressing A. Teleoperation of the robot is automatically paused if the headset is removed. Control the mobile base #Use the thumbstick/trackpad to control the mobile base!
The left controller controls the translation of the mobile base, while the right one controls the rotation.
Is there any security to prevent collision with objects?
Yes! If you are too close to a wall or object, the LIDAR anti-collision safety unables the mobile base to go closer to the obstacle. The mobile base will therefore not move in this direction, but you can still go in other directions. You will get a warning message when the anti-collision safety is triggered.
More information on the anti-collision safety
Nevertheless, this security is for the mobile base and won\u0026rsquo;t prevent the robot\u0026rsquo;s arms to collide with external objects, so be aware while teleoperating the robot.
Please note very small objects won\u0026rsquo;t be detected by the LIDAR sensor.
What is the forward direction of Reachy?
The forward direction is aligned with the forward direction of the mobile base, meaning that giving a forward instruction to the robot will always lead the robot to go physically forward, no matter the direction you are looking to.
Check the actual direction of your commands using the indicator at the bottom: the white arrow shows you the direction command relative to your actual head orientation. If your head is correctly aligned with the mobile base forward direction, this arrow will point forward if giving a forward command with your left controller.
In the above images, the same forward command is sent from the left controller.
On the first image, the user is looking straight (the black arrow is located in the target view), so the white mobility arrow is pointing front.
On the second image, the user is looking on the left side (the target view is on the left of the black arrow), so the forward direction is pointing right, as it is the direction aligned with the mobile base forward direction.
Note that these images are only for example, mobility is not available on virtual Reachy.
Use Reachy\u0026rsquo;s emotions #Use of the antennas emotion is not available on Reachy 2.
Application features #Connection page #\u0026gt; Add a new robot Click on the robot to select to open the panel of all saved robots:
Then click on "Add new robot +" at the bottom right of the page:Enter a robot name and the IP address of the robot (if the headset is connected on a computer, use the computer keyboard), and save your robot card: *The IP address is mandatory. If no name is given to the new robot, it will be called @Reachy by default*\u0026gt; Modify an existing robot Click on the robot to select to open the panel of all saved robots:
Then click on the pencil icon of the robot you want to modify:Modify the info on the robot card and save the card:\u0026gt; Delete a saved robot Click on the robot to select to open the panel of all saved robots:
Then click on the bin icon of the robot you want to delete:Validate the deletion:Mirror scene #\u0026gt; Check robot status Open the info menu in the mirror room:
The connection and services status, and motor temperature are reported here.\u0026gt; Controller mapping Open the help menu in the mirror room:
The mapping of the controller buttons to the robot actions are displayed here.\u0026gt; Settings menu Open the settings menu in the mirror room:
Here you can set your size to improve the mapping between your movements and reachy's motion. Individual parts of the robot can be deactivated in the case you don't need the mobile base, a specific arm, etc. Motion sickness options are available in this panel: choose to display a reticle or not, and select a navigation effect that fit to your robot use.You can also modify the grasping mode there: with full control you decide at each time the opening of the gripper, while the grasping lock option enables you to close the gripper with on trigger press and open it with another one. Grasping lock option can be turned on/off as well in the emotion menu.\u0026gt; Reset position While facing the mirror, your body should be aligned with Reachy\u0026rsquo;s body. This is mandatory to have a consistent control. If this is not the case after having pressed \u0026ldquo;Ready\u0026rdquo;, face the mirror and click on \u0026ldquo;Reset position\u0026rdquo;.
The "Reset position" button is placed at the bottom of the mirror, under the A loader.Teleoperation exit #\u0026gt; Exit and lock position While press (A) to exit the teleoperation, you may hold (X) to activate the position lock. A lock is displayed when doing so.
The robot will stayed locked while you'll be back in the mirror room. This can be useful to keep a certain position while you need to take a break, change position or remove the headset. The position of the robot will be displayed by the semi-transparent green robot when you will restart the teleoperation.`}),e.add({id:38,href:"/vr/use-teleop/messages/",title:"Teleoperation messages",description:"Understand warning and error messages in the VR teleoperation app",content:`During Reachy teleoperation, several messages can show up in front of view.
Warning messages
Some messages are just warnings, signaling you the quality of teleoperation may be altered or the current state of the robot may evolve into future errors (motors heating up or low battery). These messages are displayed on a dark grey background.
When possible, please consider acting to prevent these warnings from becoming errors.
Error messages
Other messages may signal errors, which will lead to a fast dysfunction of the teleoperation. These messages are to take into account quickly, as you may not be controlling the robot properly anymore when they appear. These messages are displayed on a red background.
👉🏾 When error messages appear, stop teleoperation and act conquently to protect your robot. `}),e.add({id:39,href:"/vr/use-teleop/commands/",title:"Commands",description:"Controller inputs mapping for VR teleoperation",content:`Oculus Quest #Name Feature description A At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu B During teleoperation: Mobile base boost X During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (A pressed): Lock robot position Left Thumbstick During teleoperation: Control mobile base translation Right Thumbstick During teleoperation: Control mobile base rotation If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation Valve Index #Name Feature description A right At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu A left During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (right A pressed): Lock robot position B right During teleoperation: Mobile base boost Left Thumbstick During teleoperation: Control mobile base translation Right Thumbstick During teleoperation: Control mobile base rotation If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation HTC Vive #Name Feature description Sandwich menu right At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu Sandwich menu left During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (right menu pressed): Lock robot position Left Trackpad During teleoperation: Control mobile base translation Right Trackpad During teleoperation: Control mobile base rotation Center click: Mobile base boost If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller right position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation `}),e.add({id:40,href:"/vr/use-teleop/best-practice/",title:"🚨 Best practice",description:"Simple guidelines to follow for a good usage of the VR teleoperation app",content:` 👉🏾 This page contains really important information about the use of the teleoperation app. Please make sure you read it carefully before teleoperating Reachy. Using teleoperation application has nothing complicated, but you need to respect a few guidelines to avoid damaging the robot when using it. This page goes through the main elements you need to keep in mind while teleoperating Reachy. The guidelines are not exhaustive, but should give you a good start on how to safely use the application.
Ideal use of teleoperation #The ideal position to start teleoperation may depend on the surrounding of Reachy. Nevertheless, if the robot environment is compatible with it, we advise to start with the elbows at 90 degrees, lightly away from the torso.
Here is a video of movements and positions that are suitable for teleoperation:Your browser does not support the video element.
Follow all the elements described in the next sections to teleoperate Reachy in the best conditions! All guidelines in video #Watch this quick video to have an overview of the main guidelines to use teleoperation:
The next sections go deeper into each guideline presented in the video and the risks of not following them.Keep the right position #The mapping between your position and the robot is made when holding (A) to start teleoperation. The position and rotation of your headset at this moment are used to calibrate the system. If you move (i.e. change either your body position or orientation), the controllers positions will still be calculated in this coordinate system, and Reachy movements won\u0026rsquo;t look like like yours anymore. For these reasons, you must:
Not move your feet when teleoperating Reachy: they must stay static on the floor. Your browser does not support the video element.
Your browser does not support the video element.
Not rotate your torso. In fact, Reachy\u0026rsquo;s torso won\u0026rsquo;t move, only the arms will try to reach the positions, and this may lead to collision between the Reachy\u0026rsquo;s arms and torso. Your browser does not support the video element.
Your browser does not support the video element.
Avoid movements discontinuities #Reachy doesn\u0026rsquo;t have the exact same degrees of freedom as you have, neither the same range for each joints. When a position cannot be reached, either because of the position or the orientation, the inverse kinematics gives the closest arm configuration found. The closest configuration found for the next position may be:
the same as the previous one, so the arm won\u0026rsquo;t move and you have the impression Reachy is not following your movements anymore quite different from the previous one, which will lead to sudden changes of the arm position All this contribute to give movements that seem incontrollable, due to discontinuities in the arm\u0026rsquo;s inverse kinematics.
To avoid this situation:
Avoid using extreme joints orientations while teleoperating Reachy Avoid unusual arm positions, there are probably above Reachy\u0026rsquo;s joints limits Your browser does not support the video element.
Your browser does not support the video element.
The most limiting joint is the elbow: avoid working to close to your chest, the elbow will be at the limit of its range of motion Your browser does not support the video element.
Your browser does not support the video element.
If the robot seems to stop following your movements, do not continue to move in this direction, you have already reached its workspace limit. Go back to a position you know can be reached. Avoid damaging motors #Reachy\u0026rsquo;s arms have been designed to manipulate objects at a table level and nearby. Some positions away from this nominal area can require a lot of effort from the motors to be maintained, and cause them to overheat fast. Moreover, manipulating objects requires more effort from the motors.
To avoid damaging motors:
Avoid doing movements above your head Avoid keeping your arms straight ahead horizontally to the floor, where the shoulders motors have to carry all the weight of the arms in a static position Your browser does not support the video element.
Your browser does not support the video element.
Do not let the motors in stiff mode when you are in the menu if you are not going to teleoperate the robot soon Do not try to lift objects that are above Reachy\u0026rsquo;s capabilities. If you try to lift an object and see that Reachy\u0026rsquo;s arm can follow your movement or if you head some crackling noise coming from the motors, it probably means that the object is too heavy for Reachy\u0026rsquo;s arm. Your browser does not support the video element.
Your browser does not support the video element.
Avoid damaging 3D parts #Hitting Reachy\u0026rsquo;s arms on objects can break 3D parts of the robot. It may happen even if the arms crash into something at moderate speed.
To avoid damaging 3D parts:
Check the environment surrounding the robot before starting the teleoperation. Make sure you have enough space around the robot and that there is no object to be hit by the robot (this may also save your object from being broken\u0026hellip;) Your browser does not support the video element.
Your browser does not support the video element.
Stop teleoperation close to the position which will be reached when the motors will be compliant, so that the arms won\u0026rsquo;t fall from high. Your browser does not support the video element.
Your browser does not support the video element.
Use teleop safely #Check the environment around you before starting teleoperation. Your browser does not support the video element.
Your browser does not support the video element.
Stop teleoperation before removing your headset! You must be back in the menu before dropping the controllers and removing your headset, because Reachy will continue following your movements until you stop it. Your browser does not support the video element.
Your browser does not support the video element.
Familiarize yourself with the robot #Before teleoperating the actual robot, familiarize yourself with its movements, its workspace and its joints limits. The virtual robot in the mirror scene is a good opportunity for that. Stay near the robot for your first trials: listen to the motors sounds, be aware of your workspace and field of view in a environment you know, try to manipulate light objects. Explore your own workspace with small and quite slow movements to see how the robot reacts and better understand the relation between your movements and its. 💡 You may feel like being in a video game at some point, but never forget that your movements are reproduced in real life! `}),e.add({id:41,href:"/vr/use-teleop/",title:"Use Teleop",description:"How to use the VR application to teleoperate Reachy correctly",content:""}),e.add({id:42,href:"/vr/problem/debug/",title:"Debug",description:"Meeting a problem with teleoperation? Find out what can cause this and how to resolve the situation by yourself",content:`Check the info on the app! #Connect to the robot to get more information on the connection status and the status of the robot. Open the \u0026ldquo;info\u0026rdquo; menu on the left of the mirror.
The connection status give you information about the communication with the robot. Existing connection status are the following:
Connected to a remote Reachy (green): everything seems to be working fine Connected to a remote Reachy. No restart available (yellow): you do not have access to the restart service, but can use normally teleoperation Connected to a remote Reachy. Mobile base unavailable (purple): the configuration of your robot declares a mobile base, but no mobility service is available. You can still teleoperate the robot with no mobility. Trying to connect (blue): the app is looking for the connection with the robot Robot connection failed (orange): you are connected to a remote robot, but either the camera feed or the data stream failed. Teleoperation is not possible Unable to connect to remote server (red): no robot or service is detected after trying to connect You can also check which services are available:
Camera: camera service from the cameras. Mandatory for teleoperation (except for single arm configuration) Joints data: joints services for sending and receiving data from the robot\u0026rsquo;s joints. Mandatory for teleoperation Mobility: services to control the mobile base, available only on robots equipped with a mobile base The app doesn\u0026rsquo;t connect to the robot #If you are not connected to the robot, the reason can be one of the following:
you are not connected to the right IP address the robot is not connected to the network the services are not working on the robot (either not launched or crashed) your computer is not connected to the network the connection is not stable enough for the app to stay connected to the robot Reachy never comes to be ready #First of all, check that the application managed to connect to the robot.
The connection status with the robot is indicated at the top of the mirror. Camera view (top right) is not available if the connection failed.
Connected to the robot Unable to connect to the robot The robot doesn\u0026rsquo;t move properly #Reachy movements are shifted from my real movements
Your head was probably not correctly aligned with your body when you fixed your position, or you moved since the validation step.
Come back to the mirror and validate your choices again to be able to fix a new position.
Reachy movements are jerky
The connection is not fast enough between the robot and your computer, or another program may be alterating the reactivity.
A warning message may also be displayed during teleoperation indicated the network is either unstable or has low speed.
The movements of the robot seem not correlated anymore with mine
If a motor is overheating, it may have stopped working, which can lead in movements looking very different than yours. In reality, the arm is still trying to move according to yours, but the unmoving joints make the configuration of the arm hard to understand.
In most of the cases, an error message should be displayed in the teleoperation, telling that at least 1 motor is in critical error.
Nevertheless it may happen that no error message is displayed, if the motor stopped working before having time to send the information to the teleoperation app: in that case, you received a warning message telling at least 1 motor was heating up previously during teleoperation. Check the temperature of the motors in the Info panel of the transition room.
The mobile base doesn\u0026rsquo;t move #Several elements can make the mobile base unreactive to your inputs.
If you are too close to a wall or object, the LIDAR anti-collision safety unables the mobile base to go closer to the obstacle. The mobile base will therefore not move in this direction, but you can still go in other directions. More information on the anti-collision safety The mobility button has been disabled: to check the status of the mobility button, go in the help panel in the menu (welcome page). Set the mobility to ON. The mobility services are unavailable: check the status of the service in the help panel of the menu. The status of the mobility services is displayed in the info menu. The configuration of your robot does not declare a mobile base, therefore the teleoperation application does not provide any mobility service. Check if a mobile base is expected in the Robot detected configuration section. `}),e.add({id:43,href:"/vr/problem/support-vr/",title:"Support VR",description:"Get support from the community or Pollen Robotics if you meet problems with the VR teleoperation app",content:`Discord #Join our Discord if you have any questions, maybe someone has already asked the same question or other people could benefit from the answer!
👉 Any questions relative to your development with Reachy?Join the Pollen Community on Discord Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:44,href:"/vr/problem/",title:"Problem",description:"Resolve problems you get using VR teleoperation application",content:""}),e.add({id:45,href:"/vr/introduction/introduction/",title:"Introduction",description:"What is VR teleoperation application?",content:`The Virtual Reality (VR) teleoperation application enables you to control the robot remotely with VR device.
By connecting to your robot, the teleoperation application gives you the ability to move Reachy\u0026rsquo;s arm with the tracking of the VR controllers, to rotate Reachy\u0026rsquo;s head following your own head movements and to see through Reachy\u0026rsquo;s cameras.
You can also manipulate objects remotely controlling Reachy\u0026rsquo;s grippers with your controllers\u0026rsquo; triggers.
`}),e.add({id:46,href:"/vr/installation/",title:"What needs to be installed",description:"How to install the VR teleoperation application",content:` 👉 Reachy 2021/2023 is already fully compatible with the teleoperation application. You have nothing to install on the robot. ⬇️ Download the latest version of the app On the Oculus Quest 2 #There are two options for this device: use it natively on the headset or run it on your computer using an Oculus link. If you want to use the Oculus Link, please refer to the On Windows computer section. To use it natively, choose one of the following options to install it.
From the Quest Store #Contact us on our discord channel to be added to the list of the beta testers.
Using the apk #Download the apk from our github repo, and install it to your device with your favorite tool (with the meta quest developer hub for instance).
On the Windows computer #Make sure that your VR device is properly installed and running (please refer to your device documentation).
Download the zip archive from our github repo, and unzip it. Simply launch the TeleopReachy.exe file to start the application.
`}),e.add({id:47,href:"/vr/compatibility/pc-requirements/",title:"PC Requirements",description:"Get minimal VR requirements for the teleoperation app to run",content:`The application is built on Unity 2020.3 LTS for which the requirements can be found here.
💡 Note that the app can run natively on Oculus Quest 2. In that case a computer is not required. In order to use the desktop version of the teleoperation application, your PC needs to support Virtual Reality. We recommend the computer to run on Windows, to be powerful enough and equipped with a graphic card.
The computer minimum requirements are the following:
Operating System: Windows 10 (or Windows 7 SP1) Processor: Intel Core i5-4590/AMD FX 8350 equivalent or better Memory: 8GB RAM Graphic card: NVIDIA GeForce GTX 970, AMD Radeon R9 290 equivalent or better Network: Broadband Internet connection. It is highly recommended for your PC to be hard-wired into your router using an ethernet cable. `}),e.add({id:48,href:"/vr/compatibility/headsets/",title:"Headsets",description:"Get the list of compatible VR headset to use the VR teleoperation app",content:`So far, the VR teleoperation application has been tested with the following devices:
Meta Quest 2 (with Oculus Link) Meta Quest 3 (with Oculus Link) No native application for Meta Quest headsets has been released at the moment.
The application should also support any device compatible with Unity 2022.3 including but not limited to the following devices:
Valve Index HTC Vive Oculus Rift Please refer to Unity documentation for more information about the compatibility.
`}),e.add({id:49,href:"/vr/compatibility/",title:"Compatibility",description:"Get compatible VR headsets and minimal PC requirements for the teleoperation app to run",content:""}),e.add({id:50,href:"/vr/",title:"VR app compatibility",description:"Use systend services with Reachy.",content:""}),e.add({id:51,href:"/help/system/find-my-ip/",title:"Find Reachy 2's IP",description:"How to find Reachy 2 IP address",content:`Here are 4 different options to find out the IP address of your robot.
Make sure your robot has already been connected to a network before trying to get its IP address.
LCD display screen #If you haven\u0026rsquo;t unplugged it, the LCD screen connected in Reachy\u0026rsquo;s back should be diplaying its IP address.
Hard-wired connection #Use the appropriate cable and connect your computer directly to Reachy 2\u0026rsquo;s computer. The cable has to be plugged in port (b) of Reachy 2\u0026rsquo;s hardware interface.
We use tiofor the serial connection. If you haven\u0026rsquo;t installed it yet on your computer: apt install tio
👉 Make sure dialout is in your groups, otherwise add it to your groups. To check it: \u003e\u003e\u003e groups If it doesn't appear in the list, add it with: \u003e\u003e\u003e sudo usermod -aG dialout \$USER Once connected, open a terminal on your computer and run:
tio /dev/ttyUSB0Note that depending on the elements you connected to the robot, the port could be something else than ttyUSB0. Check other available serial ports with ls /dev/ttyUSB*
👉 Login: bedrock Password: root You should then be connected to Reachy\u0026rsquo;s computer via serial port.
You can find the IP address with:
ifconfigIn our case, Reachy 2\u0026rsquo;s IP is \u0026ldquo;192.168.86.56\u0026rdquo;.
Using the serial number #Find the serial number of your robot on its back, connect your computer on the same network as your robot, open a terminal and type:
ping \u0026lt;robot.serial.number\u0026gt;.localFor example, if the serial number is reachy2-beta0003:
ping \u0026lt;reachy2-beta0003\u0026gt;.localUsing a smartphone #The Fing app let you scan IPs directly from your smartphone.
To use it, install the app on your smartphone and connect your smartphone on the same network as the robot, then run an analysis of the network to find out the IPs connected. Reachy 2 must be one of them!
`}),e.add({id:52,href:"/help/system/",title:"System",description:"Resolve most common difficulties and problems with the robot",content:""}),e.add({id:53,href:"/help/help/support/",title:"Support",description:"Get support for your Reachy robot.",content:`Forum #Join our forum if you have any questions or simply want to take a look at others topics!
👉 Any questions relative to your development with Reachy?Go to Pollen Community Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:54,href:"/help/safety/vr-use/",title:"Use VR teleoperation",description:"Guidelines to use the VR teleoperation app safely, for you, the robot and the surrounding people",content:`Watch all guidelines in video! #Watch this quick video to have an overview of the main guidelines to use teleoperation:
`}),e.add({id:55,href:"/help/safety/correct-use/",title:"Use Reachy properly",description:"Guidelines to use Reachy safely, for you and the robot",content:`Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programming it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
Your browser does not support the video element.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand as in the video above. It cannot be controlled with code, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You should hear a small noise coming from a motor in stiff mode, especially if you try to move it with your hands, it\u0026rsquo;s totally normal. Your browser does not support the video element.
Check out the Python SDK section on how to switch between the two modes.
🚨 What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, mind the obstacles that could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to use the motor\u0026rsquo;s switch in Reachy\u0026rsquo;s back to immediately turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
Good practices #Here is a non-exhaustive list of things to remember when you are using your Reachy, in order to make it last as long as possible.
Make sure that the robot is turned off and that the power supply is disconnected when you are not using it. Remember not to let the motors in stiff mode if you don\u0026rsquo;t plan to make them move. Even letting the arms on a table and in stiff mode for quite some time might damage them. Check that no obstacles will be on Reachy\u0026rsquo;s way when it will try to move. Sending commands to Reachy\u0026rsquo;s arms with an obstacle on the way will make the motors force as much as they can. Being in this kind of situation might happen but when this does, remember to turn off the motors immediately using the switch button in Reachy\u0026rsquo;s back. `}),e.add({id:56,href:"/help/safety/",title:"Safety",description:"Use the robot safely in any situation",content:""}),e.add({id:57,href:"/help/help/debug/",title:"Debug",description:"Debug",content:`Problem with the motors #The motors are managed by the reachy2-core service.
Check all logs of the service with:
journalctl -b -u reachy2-coreProblem with the cameras or sound #With teleoperation application #During teleoperation, the cameras and sound are managed by the webrtc service.
This service is automatically launched when you start Reachy 2 computer.
If you have switched between the Python SDK and the teleoperation application without robot rebooting, first make sure:
that any running client to the sdk has been disconnected that the speaker has been plugged back that the webrtc services has been restarted Check all logs of the service with:
journalctl -b -u webrtcWith the Python SDK #If you are using the cameras with the Python SDK, the cameras are then managed by the reachy2-core service.
First make sure you have enabled correctly the cameras for the SDK
Check all logs of the service with:
journalctl -b -u reachy2-core`}),e.add({id:58,href:"/help/",title:"Help",description:"Get help and support for Reachy.",content:""}),e.add({id:59,href:"/sdk/mobile-base/safety/",title:"Anti-collision safety",description:"LIDAR based anti-collision behaviour for the mobile base.",content:`Overview #The basic idea is that the LIDAR is used to detect surrounding obstacles and reduce or nullify speed commands that would create a collision with the mobile base.
Your browser does not support the video element.
The safety is active regardless of how you command the mobile base (teleop, controller, goto and set_speed).
⚠️ The safety only works with obstacles that can be seen by the LIDAR. Small obstacles that are below the LIDAR won\u0026rsquo;t be seen. Similarly, the LIDAR will see the legs of a table, but not the table top.
💡 We recommend that you get a feel of how this safety works by moving around with the controller see (getting started). Drive slowly into a wall, the mobile base should slow down and then stop. The safety should prevent the collision even when driving into the wall at full speed, which we do not recommend though :).
Detailed behaviour #Your browser does not support the video element.
If an obstacle is present inside of the critical distance boundary, then the speed of the mobile base is reduced in all directions, and nullified in the direction that would cause a collision. Rotations are slowed down but are still allowed. Otherwise, if an obstacle is present inside of the safety distance boundary, then the speed of the mobile base is reduced only in the directions that would eventually cause a collision. Rotations are unchanged. Obstacles that are further away than the safety distance do not trigger the safety in any way 💡 Reachy\u0026rsquo;s design allows the LIDAR to see close to 360° around it, but not entirely because of the metal bar: this creates a small blind spot. Even if a collision would be very unlikely (you\u0026rsquo;d have to e.g. drive backwards onto a perfectly aligned pole), any speed command that could create an unseen collision are slowed down.
⚠️ Do not obstruct the LIDAR by placing an objet on top of the mobile base as it will be considered as an obstacle.
⚠️ If the LIDAR disconnects during usage or if its controller crashes, then the mobile base will stop and will reject commands.
Advanced tuning #The mobile base\u0026rsquo;s Hardware Abstraction Layer runs with the anti-collision behaviour active by default. Currently, disabling/enabling the safety is the only configuration you can make using the SDK. If you need to fine tune the behaviour, you\u0026rsquo;ll have to interact with the world of ROS and change the HAL parameters (you\u0026rsquo;ll have to recompile the package for the changes to take effect).
The code can be accessed here.
`}),e.add({id:60,href:"/sdk/mobile-base/moving-the-base/",title:"Moving the mobile base",description:"Presentation of the different functions available to make the mobile base move",content:`Frame conventions #REP 105 “Coordinate Frames for Mobile Platforms” #Our design is coherent with ROS\u0026rsquo; conventions described in REP 105 “Coordinate Frames for Mobile Platforms”
Robot frame #The robot frame or egocentric frame or base_link frame is rigidly attached to the robot. Its (0, 0) point is the projection on the floor of the center of the mobile base. X in front, Y to the left, Theta positive counterclockwise.
Odom frame #The odom frame is a world-fixed frame. The position (x, y, theta) of the robot in the odom frame is continuously updated by the HAL through odometry calculations. These calculations currently only use the measurements from the wheels to estimate the movement of the robot. While the position of the robot is continuous, it should never be relied upon for long-term reference as it will always drift.
The initial position of the odom frame matches the position of the robot when the HAL was started. The odom frame can also be reset to the current position of the robot using:
reachy_mobile.mobile_base.reset_odometry()Moving the mobile base #There are two interfaces in the SDK to control the mobile base: spamming speed commands or setting a goal position in the odom frame.
Using the set_speed method #Since the mobile base is holonomic, the set_speed method expects 3 speed commands expressed in the robot frame:
x_vel, in m/s. The instantaneous speed positive in front of the robot. y_vel, in m/s. The instantaneous speed positive to the left of the robot. rot_vel, in deg/s. The instantaneous rotational speed positive counterclockwise. See the joy_controller code for a working example.
💡 As a safety measure, the HAL will stop the wheels if it didn\u0026rsquo;t receive a new goal speed in the last 200ms.
💡 The way this is implemented in the HAL is simply to listen to the /cmd_vel topic, apply some smoothing, perform the kinematic calculations and send the speed commands to the wheels. This makes it very easy to create control interfaces using ROS, see the keyboard example or the joy controller example.
Note: the HAL has a drive mode to set speed commands for variable amounts of time. Instead of relying on a topic, it creates a service. The niche usage didn\u0026rsquo;t warrant the added complexity, so the interface with the SDK was not made. But if needed, it exists!
Using the goto method #The goto method expects a goal position in the odom frame, composed of 3 elements: x in m, y in m and theta in deg.
⚠️ The most important thing to get used to, is the fact that the odom frame is world-fixed and that the position of the robot is always updated as long as the HAL is running (the HAL is automatically started during the robot boot-up). So by default, if you ask for a goto(0, 0, 0) the robot will try to comeback to the position it was at boot-up.
To perform a goto relative to the current position of the robot, use the method reset_odometry(). For example, create an instance of reachy with:
from reachy_sdk import ReachySDKreachy_mobile = ReachySDK(host='your-reachy-ip', with_mobile_base=True)Reset the odometry frame, and ask the robot to move 50cm in front of it:
reachy_mobile.mobile_base.reset_odometry()reachy_mobile.mobile_base.goto(x=0.5, y=0.0, theta=0.0)Now, ask for a goto(0,0,0). The robot should go back to its previous position:
reachy_mobile.mobile_base.goto(x=0.0, y=0.0, theta=0.0)We recommend taking the time to play around with this concept. You can use this Jupyer notebook to explore the goto method.
By default, the robot will always try to reach the goal position, meaning that even if the robot did reach its position and you push it, it will try to come back to the the goal position again.
However, you can define two types of stop conditions through optional parameters (see the above Jupyter notebook for a working example).
A timeout, expressed in seconds. The robot stops the goto when the elapsed time since the start of the command is superior to the timeout. There is a default timeout that scales with the distance asked by the goto. A spatial tolerance, expressed with 4 values: delta_x (the error in m along the X axis), delta_y (the error in m along the Y axis), delta_theta (the angle error in deg) and distance (the l2 distance between the current position and the goal position in m). The robot stops the goto when it is close enough to satisfy all 4 conditions simultaneously. explored in : 💡 Note: the goto behaviour is implemented in the HAL using 3 independent PIDs, one to reduce delta_x, one for delta_y and one for delta_theta. The PIDs can\u0026rsquo;t be tuned at the SDK level, but they can at the HAL level.
`}),e.add({id:61,href:"/sdk/mobile-base/mobile-base-alone/",title:"Using the mobile base without Reachy",description:"How to use the mobile base without a Reachy",content:`There is no need to instanciate the entire Reachy stack to interact with the mobile base. Instanciating the mobile-base-sdk alone is very fast and easy:
from mobile_base_sdk import MobileBaseSDKmobile_base = MobileBaseSDK('your-reachy-ip')This will work even if the upper body is not powered (the computer has to be powered though).
Once the object \u0026lsquo;mobile_base\u0026rsquo; is implemented the syntax is the same to what has been covered in the rest of the documentation, just remove the \u0026ldquo;reachy.\u0026rdquo; keyword. For example, to read the odometry just type:
mobile_base.odometryYou can use this Jupyter Notebook example to test this.
`}),e.add({id:62,href:"/sdk/mobile-base/getting-started/",title:"Getting started with the mobile base",description:"Quick overview of the mobile base control using the Python SDK",content:`Overview #To control the mobile base, we developed a Python SDK working similarly to reachy-sdk but only for the mobile base: mobile-base-sdk. As with reachy-sdk, you can use mobile-base-sdk to connect to the base remotely from another computer, as long as your computer and Reachy\u0026rsquo;s computer are connected to the same network.
However, to avoid having to use two different Python SDks when working on Reachy mobile, we integrated the use of mobile-base-sdk in reachy-sdk so that when you\u0026rsquo;re accessing the mobile base with the reachy_mobile.mobile_base attribute, you are actually using mobile-base-sdk.
Having a dedicated SDK for the mobile base still gives the advantage of having the possibility to work on the mobile base alone. More detailed in the page Using the mobile base without Reachy.
Installation #If you did not do it yet, follow the instructions from the install page to learn how to install Reachy\u0026rsquo;s Python SDK on your computer. We recommend performing the installation in a virtual environment.
💡 You will need to make sure that you get a version of reachy-sdk \u0026gt; 0.5.1 to be able to connect to the mobile base.
Even though you used PyPi for the installation, we recommend cloning the mobile-base-sdk repository on your computer as it gives you access to many examples to learn how to use the mobile base.
Connecting to Reachy mobile #Connecting to the mobile base using Reachy\u0026rsquo;s Python SDK is as simple as connecting to Reachy. When instanciating the ReachySDK object with your Reachy\u0026rsquo;s IP as in the Hello World page, you just have to specify that you are using a mobile base.
from reachy_sdk import ReachySDKreachy_mobile = ReachySDK(host='your-reachy-ip', with_mobile_base=True)The mobile base is then accessible with the reachy_mobile.mobile_base attribute.
reachy_mobile.mobile_base\u0026gt;\u0026gt;\u0026gt; \u0026lt;MobileBase host='your-reachy-ip' - version=1.0 - battery_voltage=29.1 - drive mode=cmd_vel - control mode=open_loop\u0026gt;What is accessible on the mobile base #The following are accessible with reachy_mobile.mobile_base:
mobile base version, battery level, odometry of the base, control and drive modes, goto and set_speed methods to make the mobile base move. The section moving the mobile base details the use of the goto and set_speed methods, the odometry of the base while the advanced section explains the role of the control and drive modes.
Moving the mobile base #Using the goto method #You can move the base with just one line of code, using the goto method. For example, you can make a 90 degrees rotation:
reachy_mobile.mobile_base.reset_odometry()reachy_mobile.mobile_base.goto(x=0.0, y=0.0, theta=90.0)Okay, that was 2 lines of code, but the first one is not needed and was added for safety. The section moving the mobile base is dedicated to explaining how to move the base using the Python SDK.
Check the getting-started notebook for a detailed getting started example using the Python SDK.
Using a joystick #The best (and easiest) way to get a sense of how the mobile base moves is by moving it yourself! It is easy to do that with the joy_controller.py script where you can fully control the mobile base using an Xbox or PlayStation joystick (a controller should be included with your Reachy mobile).
To start controlling the base with joy_controller.py, just type:
cd ~/dev/mobile-base-sdk/examples/scriptpython3 joy_controller.pyThe left joystick will be used for translation and the right one for rotation.
Your browser does not support the video element.
The script reads the controller and uses the mobile-base-sdk to send speed commands to the mobile base. Don\u0026rsquo;t hesitate to take a look at the code to have an example of good practices for an app involving the base.
Hardware Abstraction Layer #In this documentation, you\u0026rsquo;ll find references to the Hardware Abstraction Layer (HAL). The HAL is the ROS2 middleware that interacts with the hardware while the SDK interacts with the HAL. This modular software architecture allows for more flexibility and a simple, high level interface. However, if you need more control or a feature that wasn\u0026rsquo;t ported to the SDK, you can interact directly with the HAL. The philosophy behind this documentation is to give an easy access to the most common usages, and to give pointers that can be useful when pursuing a more advanced usage. The HAL repository can be found here.
`}),e.add({id:63,href:"/sdk/mobile-base/drive-control-modes/",title:"Advanced",description:"Drive modes and control modes description for the mobile base.",content:`Drive modes #Overview #The drive mode impacts the way the mobile base accepts commands. We could say it\u0026rsquo;s the current state of the mobile base.
In most cases, there is no need to think about these modes or to handle them in your code. Below are the most common use cases.
If you want to use the set_speed method to spam speed commands (e.g. pilot the robot with a controller), the mode has to be manually changed to \u0026lsquo;cmd_vel\u0026rsquo;: reachy_mobile.mobile_base.drive_mode = 'cmd_vel'If you want to push the robot easily, this will set the wheels in a compliancy state: reachy_mobile.mobile_base.drive_mode = 'free_wheel'On the contrary, if you want the robot to apply a passive resistance to movement, use: reachy_mobile.mobile_base.drive_mode = 'brake'You can use this Jupyter Notebook to explore the drive modes with your mobile base.
Detailed behaviour #This section is only useful if you intend to interact directly with the Hardware Abstraction Layer (HAL).
Six drive modes are available for the mobile base:
cmd_vel: in this mode, speed instructions can be spammed to the wheels controllers. This mode is used for the set_speed method. brake: in this mode, the wheels will be stiff. free_wheel: in this mode, the wheels will be as compliant as possible. emergency_stop: in this mode, the wheels will stop receiving mobility commands. Switching to this mode will also stop the mobile base hal code. This is a safety mode. speed: another mode to send speed instructions, but less frequently than with the cmd_vel mode. This mode is actually not used at this level (python SDK level), but is implemented at the ROS level, in case one might need it. goto: this mode is used for the goto method. note: the \u0026lsquo;speed\u0026rsquo; and \u0026lsquo;goto\u0026rsquo; modes can\u0026rsquo;t be changed by hand. The drive mode is handled automagically when requesting a set_speed or a goto.
The code for the HAL can be found here
Control modes #Overview #The control mode dictates the low level control strategy used by the mobile bases\u0026rsquo;s HAL.
Two control modes are possible:
open_loop (default mode): in this mode, the wheels are compliant and the control is smoother.
reachy_mobile.mobile_base.control_mode = 'open_loop'pid: in this mode, the wheels are stiff and the control is more precise.
reachy_mobile.mobile_base.control_mode = 'pid'💡 We recommend that you run the following Jupyter Notebook to get a feel of what the control mode does.
Detailed behaviour #Regardless of how the mobile base is piloted (goto, set_speed, controller), the HAL always ends up calculating a goal rotational speed for each wheel. The control mode only changes the used strategy to reach that rotational speed.
In the open_loop mode, a simple affine model was identified to match a PWM to a goal rotational speed. The VESC controllers then apply the PWM directly to the motors of the wheels, without any other low level control. The measures can be found here. While the model is simple, it does account for the static friction and the experimental data shows a good fit when the mobile base is on a flat surface. In the pid mode, the HAL gives the goal rotational speeds directly to the VESC controllers of each wheel. The VESC will use a PID controller to control the speeds. `}),e.add({id:64,href:"/advanced/",title:"Description",description:"Reachy's description.",content:""}),e.add({id:65,href:"/sdk/introduction/introduction/",title:"Introduction",description:"Quick overview of the Python SDK and of the other options available to control the robot.",content:`The SDK in a nutshell #The Python SDK lets you easily control and program a Reachy robot. It is used to read information (eg. camera image or joint position) and send commands to make the robot move.
It is designed to:
let you start controlling your robot in a few lines of codes, allow to focus on your application and not on hardware synchronisation issues, facilitate fast prototyping and iteration. Connecting to your robot and getting the up-to-date position of all joints is as simple as:
from reachy2_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPfor name, joint in reachy.joints.items():print(f'Joint \u0026quot;{name}\u0026quot; position is {joint.present_position} degree.')You can use it directly on Reachy\u0026rsquo;s computer or work remotely on another computer, as long as you are connected on the same network. The SDK works on Windows/Mac/Linux and requires Python \u0026gt;= 3.10. It is entirely open-source and released under an Apache 2.0 License.
Is this the right option for me? #The Python SDK is only one way to control Reachy. There are other options that have different pros and cons.
To know if the SDK is the right option, the TL;DR here would be something like:
You want to focus on creating an application or behavior on Reachy. You don\u0026rsquo;t want to dig into the details on how it can be controlled or run very time constrained code (eg. need more than 100Hz control). You have basic knowledge of Python (no advanced knowledge is required). You do not already have an important code base running on ROS2. The other options #Unity VR App #If you are interested in teleoperation and want to control Reachy via VR controllers, you can directly use our Unity VR App. More information on the dedicated section.
ROS2 Humble packages #Reachy runs on ROS2 Humble. ROS is a Robotic Operating System, it offers a huge variety of compatible algorithms and hardware drivers. Yet, if you are not familiar with ROS, the beginning can be a bit overwhelming.
The embedded NUC computer comes with ROS2 and Reachy specific packages already installed and running. They provide full access to Reachy (lower-level than the SDK). You can:
get the joint states and forward position controllers use Rviz subscribe to various sensor topic (camera, force sensor, etc) access client for IK/FK For more information, please refer to the dedicated section.
Custom gRPC client #If you want to use another language than Python, for instance to integrate Reachy\u0026rsquo;s control within an existing code base, you can write your own gRPC client. Our API is available here.
The API is used both by the Python SDK and the VR App.
`}),e.add({id:66,href:"/sdk/getting-started/safety/",title:"Safety first",description:"What you need to be aware of as a user to prevent Reachy from getting damaged and you from getting hurt.",content:`Especially, the screws in the Reachy\u0026rsquo;s back and the ones fixatings its metal support should be well tightened.
Turning on/off the motors #If at anytime when you\u0026rsquo;re working with Reachy you feel that you\u0026rsquo;re losing control of the robot\u0026rsquo;s movements, don\u0026rsquo;t hesitate to turn the motors off. Use the switch button placed in its back.
Also, don\u0026rsquo;t forget to turn the motors off when you\u0026rsquo;re done working with the robot.
Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programing it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand. It cannot be controlled, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You can change the compliance mode of a joint with its compliant attribute.
reachy.r_arm.r_gripper.compliant = False # stiff modereachy.r_arm.r_gripper.compliant = True # compliant modeor if you prefer to change the compliance of all the joints in a part of Reachy (left/right arm or the head), you can use the turn_on() and turn_off() methods.
turn_on() puts all the joints of the requested part in stiff mode whereas turn_off() put them in compliant mode.
reachy.turn_on('r_arm')Try this on your robot to feel the resistance applied by the right arm\u0026rsquo;s motors in stiff mode. You can compare with the left arm which should be in compliant mode. You should hear a small noise coming from the right arm\u0026rsquo;s motors, especially if you try to move them with your hands, it\u0026rsquo;s totally normal when they are in stiff mode.
If you want to the right arm\u0026rsquo;s motors back to compliant mode:
reachy.turn_off('r_arm')What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, be careful to obstacles that you could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
`}),e.add({id:67,href:"/sdk/getting-started/install/",title:"Installation",description:"How to install the Python SDK, either from PyPi or directly from sources.",content:`How to install the Python SDK #The Python SDK is a pure Python library. The installation should thus be rather straightforward. It supports Python \u0026gt;= 3.10 (older versions will not work because of typing syntax). It works on Windows/Mac/Linux.
We recommend to use virtual environment for your development. They make the installation simple and avoid compatibility issues. They also come with their pip command.
From PyPi #pip3 install reachy-sdkFrom the source #git clone https://github.com/pollen-robotics/reachy-sdkpip3 install -e reachy-sdkDependencies #The SDK relies on a few third-party Python packages:
numpy - mostly for trajectory computation opencv - for camera frame access grpc - to connect to the robot They will be installed automatically when you install the SDK.
`}),e.add({id:68,href:"/sdk/getting-started/hello-world/",title:"Hello World",description:"First SDK connection with your Reachy",content:`Enable cameras for the SDK #SR camera #The SR camera is unplugged by default.
If you want to use it, plug the SR camera on the robot\u0026rsquo;s computer remaining USB port (2).
Make sure to unplug it if you want to use the teleoperation.
Teleop cameras #The teleop cameras are shared between the teleop service and the SDK server, and can only be used by one at the same time.
In order to be able to use the teleop cameras with the SDK:
Go to the dashboard Stop webrtc service in the services tab Connect to your robot #Now you should be able to connect to your Reachy 2 and check that everything is ok. As we spoiled in the previous section, to connect to your robot, you simply need to run the following code:
from reachy2_sdk import ReachySDK# Replace with the actual IP you've found.reachy = ReachySDK(host='the.reachy.ip.found.')Before diving into the next chapters that will guide you in the depth of what you can do with the Reachy SDK, here is a quick preview.
Getting joints state #To make sure everything is working fine, let\u0026rsquo;s check the position of its joints. We won\u0026rsquo;t go into details here as we will detail everything later.
To get the state of a joint, you can access the joints attribute that contains all joints and iterate over its content:
for name, joint in reachy.joints.items(): print(f'Joint \u0026quot;{name}\u0026quot; is at pos {joint.present_position} degree.') Will show something like:
Joint \u0026quot;r_arm.shoulder.pitch\u0026quot; is at pos -3.6 degree.Joint \u0026quot;r_arm.shoulder.roll\u0026quot; is at pos 1.5 degree.Joint \u0026quot;r_arm.elbow.yaw\u0026quot; is at pos -3.1 degree.Joint \u0026quot;r_arm.elbow.pitch\u0026quot; is at pos 2.0 degree.Joint \u0026quot;r_arm.wrist.roll\u0026quot; is at pos -54.4 degree.Joint \u0026quot;r_arm.wrist.pitch\u0026quot; is at pos -0.9 degree.Joint \u0026quot;r_arm.wrist.yaw\u0026quot; is at pos -20.7 degree.Joint \u0026quot;l_arm.shoulder.pitch\u0026quot; is at pos 43.0 degree.Joint \u0026quot;l_arm.shoulder.roll\u0026quot; is at pos 0.8 degree.Joint \u0026quot;l_arm.elbow.yaw\u0026quot; is at pos 0.5 degree.Joint \u0026quot;l_arm.elbow.pitch\u0026quot; is at pos 1.2 degree.Joint \u0026quot;l_arm.wrist.roll\u0026quot; is at pos 0.1 degree.Joint \u0026quot;l_arm.wrist.pitch\u0026quot; is at pos 0.1 degree.Joint \u0026quot;l_arm.wrist.yaw\u0026quot; is at pos 1.1 degree.Joint \u0026quot;head.neck.roll\u0026quot; is at pos 4.5 degree.Joint \u0026quot;head.neck.pitch\u0026quot; is at pos -0.7 degree.Joint \u0026quot;head.neck.yaw\u0026quot; is at pos -1.9 degree.Note that we have accessed the attribute present_position to get the joint actual position. You can access the position of a specific joint by using its full name (meaning the part it is attached to plus its name). For instance, to get the position of the \u0026rsquo;left shoulder pitch':
\u0026gt;\u0026gt;\u0026gt; print(reachy.l_arm.shoulder.pitch.present_position)-3.6You can also get a resume of the joint state by doing:
\u0026gt;\u0026gt;\u0026gt; print(reachy.l_arm.shoulder.pitch)\u0026lt;OrbitaJoint axis_type=\u0026quot;pitch\u0026quot; present_position=-3.6 goal_position=0.0\u0026gt;If you did not run anything else, your robot should be compliant (meaning you can freely move it). You can try to move it and re-run the code above. You should see that without doing anything specific, the positions are automatically updated.
Seeing through Reachy 2\u0026rsquo;s cameras #Assuming, you are still connected (otherwise, simply reconnect), we will now display what Reachy sees as an OpenCV window.
import cv2 as cvwhile reachy.cameras.teleop.capture():l_frame = reachy.cameras.teleop.get_frame(CameraView.LEFT)r_frame = reachy.cameras.teleop.get_frame(CameraView.RIGHT)cv2.imshow(\u0026quot;left\u0026quot;, l_frame)cv2.imshow(\u0026quot;right\u0026quot;, r_frame)cv2.waitKey(1)You should now see what Reachy sees!
To stop the code, press Ctrl-C.
`}),e.add({id:69,href:"/sdk/getting-started/connect/",title:"Connect to Reachy 2",description:`The last required step before being able to use your Reachy 2 is to find its IP address.
Note: if you haven\u0026rsquo;t connected Reachy to a network yet, please first follow the instructions ???
Using the LCD screen #If you haven\u0026rsquo;t unplugged it, the LCD screen connected in Reachy\u0026rsquo;s back should be diplaying its IP address.
If the LCD screen is not working or is unplugged, check out the page Find my IP section to learn other ways to get the IP address.`,content:`The last required step before being able to use your Reachy 2 is to find its IP address.
Note: if you haven\u0026rsquo;t connected Reachy to a network yet, please first follow the instructions ???
Using the LCD screen #If you haven\u0026rsquo;t unplugged it, the LCD screen connected in Reachy\u0026rsquo;s back should be diplaying its IP address.
If the LCD screen is not working or is unplugged, check out the page Find my IP section to learn other ways to get the IP address.
You can check that everything is working as expected by running the following Python code:
from reachy_sdk import ReachySDK# Replace with the actual IP you've found.reachy = ReachySDK(host='the.reachy.ip.found.')`}),e.add({id:70,href:"/sdk/getting-started/overview/",title:"SDK Overview",description:"Understand the structure of the SDK.",content:`Understand the SDK structure #Reachy #Parts #Actuators #Reachy\u0026rsquo;s arm offers 7 degrees of freedom. It also gives access to one joint for the gripper.
The arm is divided as follow:
shoulder, composed of 2 joints (pitch and roll) elbow, composed of 2 joints (yaw and pitch) wrist, composed of 3 joints (roll, pitch and yaw) We refer to the shoulder, elbow and wrist as actuators.
For some actions, such as changing the compliance, is the the lowest level of control you will have.
Joints #Each degree of freedom of Reachy is referred to as a joint. Joints are the lowest level of control you can have.
The Orbita2D (used as shoulders and elbows in Reachy 2) offer the control of 2 joints, while Orbita3D (used as wrists and neck) offer the control of 3 joints.
A joint is an angle you can control the position of in order to make movements with Reachy. For each joint, you can read a present position and write a goal position. Those position are given in degrees.
reachy.r_arm.elbow.pitch.present_position\u0026gt;\u0026gt;\u0026gt; 0.0reachy.r_arm.elbow.pitch.goal_position = -90Cameras #You have 2 different cameras type on Reachy:
the teleop cameras, which are the cameras in Reachy\u0026rsquo;s head. They are mobile cameras which can move the head and with stereovision, that are used for the teleoperation. the SR cameras, which are the short-range cameras on Reachy\u0026rsquo;s torso. They are fix cameras, with an accessible dpeth map, mainly useful for manipulation tasks. You can access those cameras doing:
reachy.cameras.teleop\u0026gt;\u0026gt;\u0026gt;reachy.cameras.SR\u0026gt;\u0026gt;\u0026gt;👉 The teleop cameras are shared between the Teleoperation service and the SDK server, and can only be used by one of them at once. Make sure you enabled the access to the teleop cameras for the SDK server before trying to use them through the Python SDK. `}),e.add({id:71,href:"/sdk/mobile-base/",title:"Mobile Base",description:"Learn how to use Reachy's mobile base.",content:""}),e.add({id:72,href:"/sdk/getting-started/",title:"Getting Started",description:"Getting Started with the SDK.",content:""}),e.add({id:73,href:"/sdk/introduction/",title:"Getting Started",description:"Getting Started with the SDK.",content:""}),e.add({id:74,href:"/sdk/first-moves/moves/",title:"2. Understand moves in Reachy 2",description:"How do moves work on Reachy 2.",content:`Moves methods #ReachySDK for Reachy 2 offers you methods to make movements with the arms and head, controlling the target position in several way, choosing the duration of the movement, or even the interpolation mode.
Those methods work the same way on the left and right arms and on the head, but not on the mobile base.
The methods to use in order to control the robot are:
for the arms: goto_joints(): you control directly the goal position of each joint of the arm, in degrees goto_from_matrix(): you control the target pose of the end effector in the robot\u0026rsquo;s coordinate system, from a 4x4 homogeneous matrix for the head: look_at(): you control the head by giving a point in the robot coordinate system the head will look at rotate_to(): you control directly the roll, pitch and yaw goal positions of the neck, in degrees orient(): you control the head orientation with a quaternion Moves properties #Moves IDs #The previous methods all return an id, that you can use to get information on this movements or to cancel this movement. Store this id in a variable to be able to use it further.
move_1 = reachy.r_arm.goto_joints([10, -10, 0, -90, 0, 0, 0])print(move_1)\u0026gt;\u0026gt;\u0026gt; ??Moves execution #Move commands can only be sent on parts:
reachy.l_arm reachy.r_arm reachy.head Moves are non-blocking for other parts #It means you can send a move command on different parts, it won\u0026rsquo;t wait for the movement to be executed on the first part to execute the other one, but will follow the timing of your code.
Let\u0026rsquo;s take an example with the following sequence:
reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)time.sleep(1)reachy.r_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 2)This sequence will take 3 seconds to execute, as the right arm will start its movement 1 second after the left arm has started its own movement. They will finish at the same time.
Moves are blocking and stacked for a part #It means that you can send several move commands on a part one after another without any delay, they will be played in this order, but will wait for the previous move to be finished.
Let\u0026rsquo;s take an example with the following sequence:
reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2)reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)This sequence will take 8 seconds to execute, as each movement on the left arm will wait for the previous before starting.
Nevertheless, you can still send move commands to other parts.
For example:
reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3) #1time.sleep(1)reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2) #2reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3) #3reachy.r_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 2) #4This sequence will still take 8 seconds to execute:
commands #1, #2 and #3 are sent to the left arm. They will be stacked on the left arm, and the time.sleep(1) won\u0026rsquo;t have any effect . When received, command #2 will simply wait 2 seconds rather than 3 secondes in the previous example. commands #4 is sent on the right arm, where no movement is progress. It will then start 1 second after command #1 has started, and will then be over approximatively at the same time. The sequence execution order is #1, #4, #2, #3
Part execution state #As the sequence can become complex, you can get information for each part on its current status, to now which movementis being played and know which others are waiting to be played.
For each part, the following methods are available:
get_move_playing(): will return the id of the currently playing move on the part get_moves_queue(): will return the ids of all stacked move commands waiting to be played on the part Those methods are called at the part level, to get info on the state of the part.
For example:
# Write a sequence for the left armreachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3) # id=1reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2) # id=2reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3) # id=3# Move #1 is currently playingcurrent_move = reachy.l_arm.get_move_playing()print(current_move)\u0026gt;\u0026gt;\u0026gt; ??# 2 move commands, #2 and #3, are waiting to be playedprint(len(reachy.l_arm.get_moves_queue()))\u0026gt;\u0026gt;\u0026gt; 2Moves state #For a specific move, you may want to know its current state. You can get information on the moves given its id with 3 methods available at reachy\u0026rsquo;s level:
is_move_playing(): return True if the movement is currently being played is_move_finished(): return True if the movement is over, but also if it won\u0026rsquo;t be played because it has been cancelled for example get_move_joints_request(): will return the joints goal positions sent to the part by the corresponding move command Let\u0026rsquo;s take an example:
move_1 = reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)time.sleep(1)# Move is currently being playedreachy.is_move_playing(move_1)\u0026gt;\u0026gt;\u0026gt; Truereachy.is_move_finished(move_1)\u0026gt;\u0026gt;\u0026gt; Falsetime.sleep(3)# Move is now overreachy.is_move_playing(move_1)\u0026gt;\u0026gt;\u0026gt; Falsereachy.is_move_finished(move_1)\u0026gt;\u0026gt;\u0026gt; True# Get joint goal position of the movereachy.get_move_joints_request(move_1)\u0026gt;\u0026gt;\u0026gt; ??Cancel moves #If you want to modify the queue of move commands on a part, or interrupt the movement being played, you can cancel move commands at any time.
Single move cancellation #To cancel a single movement, currently playing or stacked in a part\u0026rsquo;s queue, use its id and call cancel_move_by_id() from reachy.
move_1 = reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)time.sleep(1)reachy.cancel_move_by_id(move_1)Cancel all moves at once #To cancel all moves at once, you can call the cancel_all_moves() methods.
This method can be called at the level you want to act, which can be either reachy or a specific part.
All robot moves #For example, if you want to cancel all moves on all parts:
# Send a sequence of movesreachy.head.rotate_to(20, 30, -10, duration=3)reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2)# Cancel all movesreachy.cancel_all_moves()All movements are cancelled, even the movement stacked in the left arm queue which will never be played.
All part moves #If you only want to cancel movement on the left arm:
# Send a sequence of movesreachy.head.rotate_to(20, 30, -10, duration=3)reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 3)reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2)# Cancel moves on left arm onlyreachy.l_arm.cancel_all_moves()The movement on the head will continue, but all the movements of the left will be stopped and the left arm queue cleaned.
Moves duration #For each methods mentioned in Moves methods, you can give a custom duration for the execution of the movements.
Simply specify the duration argument in seconds when calling the method, as shown in the move examples above:
reachy.head.rotate_to(20, 30, -10, duration=3)reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], duration = 5)# Doing:reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0])# will lead to the same result as:reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], duration = 2)Default duration is 2 seconds.
You cannot set a duration to 0 second. This will raise an exception in your code: ??
Moves interpolation mode #The moves methods generates a trajectory between the present position and the goal position. This trajectory is then interpolated at a predefined frequency (100Hz) to compute all intermediary target positions that should be followed before reaching the final goal position. Depending on the interpolation mode chosen, you can have a better control over speed and acceleration.
Two interpolation modes are available when sending a move command:
the linear interpolation mode the minimum-jerk interpolation mode Both trajectories start and finish at the same point but don\u0026rsquo;t follow the same intermediate positions. The minimum jerk will slowly accelerate at the begining and slowly decelerate at the end. This makes the movements more natural.
You can specify the interpolation mode by setting the interpolation_mode argument when calling the method:
reachy.head.rotate_to(20, 30, -10, interpolation_mode='linear')reachy.l_arm.goto_joints([0, 0, 0, -90, 0, 0, 0], interpolation_mode='linear')# Doing:reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0])# will lead to the same result as:reachy.l_arm.goto_joints([0, 0, 0, 0, 0, 0, 0], interpolation_mode='minimum_jerk')Default interpolation mode is minimum-jerk.
`}),e.add({id:75,href:"/sdk/first-moves/record/",title:"7. Record and replay trajectories",description:`You can easily record joint trajectories directly on Reachy, store and replay them later. This page will show you how to implement such mechanisms.
All examples given below will show trajectories record on each of the robot joints. The position of each motor will be stored at a predefined frequency (typically 100Hz). Similarly, the replay will set new target position using the same frequency. Those basics examples does not perform any kind of filtering or modification of the data.`,content:`You can easily record joint trajectories directly on Reachy, store and replay them later. This page will show you how to implement such mechanisms.
All examples given below will show trajectories record on each of the robot joints. The position of each motor will be stored at a predefined frequency (typically 100Hz). Similarly, the replay will set new target position using the same frequency. Those basics examples does not perform any kind of filtering or modification of the data.
In the following examples, we will assume that you are already connected to your robot and know how to control individual motors.
Recording a trajectory #To record a trajectory, we will simply get the current position of individual motors at a predefiend frequency. We will first define a list of motors that we want to record. In this example, we will only record the joints from the right arm, but you can similarly record a single motor, or all motors of the robot at once.
# assuming we run something like this before:# reachy = ReachySDK(host='192.168.0.42') recorded_joints = [reachy.r_arm.r_shoulder_pitch,reachy.r_arm.r_shoulder_roll,reachy.r_arm.r_arm_yaw,reachy.r_arm.r_elbow_pitch,reachy.r_arm.r_forearm_yaw,reachy.r_arm.r_wrist_pitch,reachy.r_arm.r_wrist_roll,]Now let\u0026rsquo;s define our frequency and record duration:
sampling_frequency = 100 # in Hzrecord_duration = 5 # in sec.Our record loop can then be defined as such:
import timetrajectories = []start = time.time()while (time.time() - start) \u0026lt; record_duration:# We here get the present position for all of recorded jointscurrent_point = [joint.present_position for joint in recorded_joints]# Add this point to the already recorded trajectoriestrajectories.append(current_point)time.sleep(1 / sampling_frequency)If you want to record a demonstration on the robot, first make sure the robot is compliant. Then, put it in the starting position. Run the code, and start moving the robot. After 5 seconds, the loop will stop and the movements you have made on Reachy will be recorded.
Depending on your uses, you can define another duration. You can also choose not to use a specify duration but maybe use start and stop event to record. In such case, the easy way is probably to run the loop within a thread or an asynchronous fonction, so it can run in background.
Visualise your recordings #The trajectories you recorded can be converted to numpy array for more complex processings:
import numpy as nptraj_array = np.array(trajectories)If you are familiar with matplotlib, you can also plot it via:
from matplotlib import pyplot as pltplt.figure()plt.plot(trajectories)Replay a recorded trajectory #Replaying the recorded trajectory basically uses the same loop but set the goal position instead of reading the present position.
But before actually replaying the trajectory, there are a few key points that you should take care of:
First, make sure the joints you are going to move are stiff. Then, if the arm is not in the same position than the one you use as a start position of your recording, the beginning of the replay will be really brutal. It will try to go to the starting position as fast as possible. To avoid that, you can use the goto function to first go to the first point of your trajectories:
from reachy_sdk.trajectory import goto# Set all used joint stifffor joint in recorded_joints:joint.compliant = False# Create a dict associating a joint to its first recorded positionfirst_point = dict(zip(recorded_joints, trajectories[0]))# Goes to the start of the trajectory in 3sgoto(first_point, duration=3.0)Now that we are in position, we can actually play the trajectory. To do that, we simply loop over our recordings and set the goal position of each joints at the same frequency:
import timefor joints_positions in trajectories:for joint, pos in zip(recorded_joints, joints_positions):joint.goal_position = postime.sleep(1 / sampling_frequency)`}),e.add({id:76,href:"/sdk/first-moves/kinematics/",title:"4. Use arms kinematics",description:"Presentation of Reachy's forward and inverse kinematics.",content:` Note : Make sure you checked the safety page before controlling the arm.
Arm coordinate system #Joint coordinates #If you remember the goto_joint() function, to generate a trajectory for the arm, you need to pass a list of joints with the requested position as argument.
For example, to place the right arm in a right angled position, we defined the following list:
right_angled_position = [0, 0, 0, -90, 0, 0, 0]and then call the function with is:
reachy.r_arm.goto_joints(right_angled_position)In this basic arm control, we used what is called joint coordinates to move Reachy. This means that we controlled each joint separately.
Controlling a robot in joint coordinates can be hard and is often far from what we actually do as humans. When we want to grasp an object in front of us, we think of where we should put our hand, not how to flex each individual muscle to reach this position. This approach relies on the cartesian coordinates: the 3D position and orientation in space, this is where the kinematic model comes into play.
Kinematic model #The kinematic model describes the motion of a robot in mathematical form without considering the forces and torque affecting it. It only focuses on the geometric relationship between elements.
We have defined the whole kinematic model of the arm. This means the translation and rotation required to go from one joint to the next one. On a right arm equipped with a gripper this actually look like this:
Motor Translation Rotation r_arm.shoulder.pitch (0, -0.019, 0) (0, 1, 0) r_arm.shoulder.roll (0, 0, 0) (1, 0, 0) r_arm.elbow.yaw (0, 0, -0.280) (0, 0, 1) r_arm.elbow.pitch (0, 0, 0) (0, 1, 0) r_arm.wrist.roll (0, 0, -0.120) (0, 0, 1) r_arm.wrist.pitch (0, 0, 0) (0, 1, 0) r_arm.wrist.yaw (0, 0, 0) (1, 0, 0) r_gripper (0, ??, ??) (0, 0, 0) To use and understand the kinematic model, you need to know how Reachy coordinate system is defined (from Reachy\u0026rsquo;s perspective), see below:
the X axis corresponds to the forward arrow, the Y axis corresponds to the right to left arrow, the Z axis corresponds to the up arrow. The origin of this coordinate system is located in the upper part of the robot trunk, inside Reachy. Basically, if you imagine a segment going from the left shoulder to the right shoulder of the robot, the origin is the middle of this segment, which corresponds to behind the center of Pollen\u0026rsquo;s logo on Reachy\u0026rsquo;s torso.
Units in this coordinate system are meters. So the point (0.3, -0.2, 0) is 30cm in front of the origin, 20cm to the right and at the same height.
End effector location #We consider the end-effector to be in a virtual joint located in the gripper and referred as \u0026lsquo;right_tip\u0026rsquo; or \u0026rsquo;left_tip\u0026rsquo; in the urdf file, as shown below.
The red dot corresponds to the \u0026lsquo;right_tip\u0026rsquo;.
You can see the right and left end-effectors animated below.
Your browser does not support the video element.
Switching between joint and cartesian coordinates #Forward and inverse kinematics are a way to go from one coordinates system to the other:
forward kinematics: joint coordinates –\u0026gt; cartesian coordinates, inverse kinematics: cartesian coordinates –\u0026gt; joint coordinates. Forward kinematics #Using the kinematic model defined above, we can compute the 3D position and orientation of the right or left end-effector with the forward_kinematics() method.
forward_kinematics() #Each arm has a forward_kinematics() method. To use it, you first need to connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.r_arm.forward_kinematics()\u0026gt;\u0026gt;\u0026gt; array([[ 0.04622308, -0.03799621, -0.99820825, 0.31144822],[ 0.10976691, 0.99341829, -0.03273101, -0.19427524],[ 0.99288199, -0.1080573 , 0.05008958, -0.4255104 ],[ 0. , 0. , 0. , 1. ]])The method returns a 4x4 matrix indicating the position and orientation of the end effector in Reachy 2\u0026rsquo;s coordinate system.
By specifying no argument, it will give the current 3D position and orientation of the end effector.
You can compute the forward kinematics of the arm for other joints positions, by giving as an argument a seven-element-long list, as for the goto_joints()method. The arm will not move, but you can get the target position and orientation of the arm in this configuration.
For example, for the right arm right angled position:
reachy.r_arm.forward_kinematics([0, 0, 0, -90, 0, 0, 0])\u0026gt;\u0026gt;\u0026gt; array([[ 0.04622308, -0.03799621, -0.99820825, 0.31144822],[ 0.10976691, 0.99341829, -0.03273101, -0.19427524],[ 0.99288199, -0.1080573 , 0.05008958, -0.4255104 ],[ 0. , 0. , 0. , 1. ]])Understand the result #The 4x4 matrix returned by the forward_kinematics() method is what is often called a pose. It actually encodes both the 3D translation (as a 3D vector) and the 3D rotation (as a 3x3 matrix) into one single representation.
\$\$\\begin{bmatrix} R_{11} \u0026amp; R_{12} \u0026amp; R_{13} \u0026amp; T_x\\\\\\ R_{21} \u0026amp; R_{22} \u0026amp; R_{23} \u0026amp; T_y\\\\\\ R_{31} \u0026amp; R_{32} \u0026amp; R_{33} \u0026amp; T_z\\\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\$\$
The instruction
reachy.r_arm.forward_kinematics()returns the current pose of the right end-effector, based on the present position of every joint in the right arm.
You can also compute the pose for a given joints position, to do that just pass the list of position as argument of forward_kinematics. Be careful to respect the order of the position you give and to give all the joints in the arm kinematic chain (i.e. from shoulder_pitch to wrist_roll).
For example, we can compute the forward kinematics for the right-angle position we defined earlier.
reachy.r_arm.forward_kinematics(right_angle_position)\u0026gt;\u0026gt;\u0026gt; array([[ 0. , 0. , -1. , 0.3675],[ 0. , 1. , 0. , -0.202 ],[ 1. , 0. , 0. , -0.28 ],[ 0. , 0. , 0. , 1. ]])With this result, we can tell that when the right arm is in the right angle position, the right end-effector is 37cm in front of the origin, 20cm to the left and 28cm below the origin.
As of the rotation matrix, the identity matrix corresponds to the zero position of the robot which is when the hand is facing toward the bottom.
Here we obtained the rotation matrix
\$\$\\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; -1\\\\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\\\ 1 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix}\$\$
We can use scipy to understand what this matrix represents.
from scipy.spatial.transform import Rotation as Rimport numpy as npR.from_matrix([[0, 0, -1],[0, 1, 0],[1, 0, 0],]).as_euler('xyz', degrees=True)\u0026gt;\u0026gt;\u0026gt; array([ 0. , -89.99999879, 0. ])So scipy tells us that a rotation of -90° along the y axis has been made to get this matrix, which is coherent with the result because having the hand facing forward corresponds to this rotation according to Reachy\u0026rsquo;s xyz axis that we saw above.
Inverse kinematics #The inverse kinematics is the exact opposite of the forward kinematics. From a 4x4 pose in Reachy 2 coordinate system, it gives you a list of joints positions to reach this target.
Knowing where you arm is located in the 3D space can be useful but most of the time what you want is to move the arm in cartesian coordinates. You want to have the possibility to say: “move your hand to [x, y, z] with a 90° rotation around the Y axis”. This is what goto_matrix()
inverse_kinematics() #Each arm has an inverse_kinematics() method. To use it, you first need to connect to your Reachy.
You need to specify as an argument a target pose in Reachy coordinate system.
Let\u0026rsquo;s for example ask for the inverse kinematics of the current pose, using the forward kinematics.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.r_arm.inverse_kinematics(reachy.r_arm.forward_kinematics())\u0026gt;\u0026gt;\u0026gt; [0, 0, 0, -90, 0, 0, 0] ??The method returns a seven-element-long list indicating the position of each arm joint, in the usual order:
r_arm.shoulder.pitch r_arm.shoulder.roll r_arm.elbow.yaw r_arm.elbow.pitch r_arm.wrist.roll r_arm.wrist.pitch r_arm.wrist.yaw Contrary to the forward kinematics which has a unique answer (giving all joints values will always put the end effector at the same target position), inverse kinematics can have an infinite number of answers (for a target position of the end effector, several combinations of joints angles are possible).
Using a q0 value #The inverse kinematics returns one solution, but you may want to custom the position from which the computation is done to get another result.
To do so, specify a q0 value when calling the inverse_kinematics() method. The q0 argument must be a seven-element-long list as well:
reachy.r_arm.inverse_kinematics(reachy.r_arm.forward_kinematics(), q0=[0, 0, 0, 0, 0, 0, 0])\u0026gt;\u0026gt;\u0026gt; [0, 0, 0, -90, 0, 0, 0] ??Example: square movement with goto_matrix() #Defining the poses #To make this more concrete, let\u0026rsquo;s first try with a simple example. We will make the right hand draw a square in 3D space. To draw it, we will define the four corners of a square and Reachy\u0026rsquo;s right hand will go to each of them.
The virtual corner is represented below.
For our starting corner A, let\u0026rsquo;s imagine a point in front of the robot, on its right and below its base. With Reachy coordinate system, we can define such a point with the following coordinates:
\$\$A = \\begin{pmatrix}0.3 \u0026amp; -0.4 \u0026amp; -0.3\\end{pmatrix}\$\$
The coordinates of B should match A except the z component wich should be higher. Hence
\$\$B = \\begin{pmatrix}0.3 \u0026amp; -0.4 \u0026amp; 0.0\\end{pmatrix}\$\$
For the corner C, we want a point on the same z level as B in the inner space of Reachy and in the same plane as A and B so we only need to change the y component of B. We can take for example
\$\$C = \\begin{pmatrix}0.3 \u0026amp; -0.1 \u0026amp; 0.0\\end{pmatrix}\$\$
And to complete our corners we can deduce D from A and C. D coordinates should match C except its z component which must the same as A. Hence
\$\$D = \\begin{pmatrix}0.3 \u0026amp; -0.1 \u0026amp; -0.3\\end{pmatrix}\$\$
Remember that you always have to provide poses to the inverse kinematics that are actually reachable by the robot. If you\u0026rsquo;re not sure whether the 3D point that you defined is reachable by Reachy, you can move the arm with your hand in compliant mode, ask the forward kinematics and check the 3D translation component of the returned pose.
But having the 3D position is not enough to design a pose. You also need to provide the 3D orientation via a rotation matrix. The rotation matrix is often the tricky part when building a target pose matrix.
Keep in mind that the identity rotation matrix corresponds to the zero position of the robot which is when the hand is facing toward the bottom. So if we want the hand facing forward when drawing our virtual square, we need to rotate it from -90° around the y axis, as we saw in the forward kinematics part.
We know from before which rotation matrix corresponds to this rotation, but we can use scipy again to generate the rotation matrix for given rotations.
print(np.around(R.from_euler('y', np.deg2rad(-90)).as_matrix(), 3))\u0026gt;\u0026gt;\u0026gt; [[ 0. -0. -1.][ 0. 1. -0.][ 1. 0. 0.]]We got the rotation matrix that we expected!
As mentionned, building the pose matrix can be hard, so don\u0026rsquo;t hesitate to use scipy to build your rotation matrix. You can also move the arm with your hand where you want it to be and use the forward kinematics to get an approximation of the target pose matrix you would give to the inverse kinematics.
Here, having the rotation matrix and the 3D positions for our points A and B, we can build both target pose matrices.
A = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.4], [1, 0, 0, -0.3],[0, 0, 0, 1], ])B = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.4], [1, 0, 0, 0.0],[0, 0, 0, 1], ])C = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.1], [1, 0, 0, 0.0],[0, 0, 0, 1], ])D = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.1], [1, 0, 0, -0.3],[0, 0, 0, 1], ])Sending the movements commands #As before, we use the goto_matrix() to send moving instructions to the arm.
import time# put the joints in stiff modereachy.r_arm.turn_on()# use the goto_matrix() methodreachy.r_arm.goto_matrix(A)reachy.r_arm.goto_matrix(B)reachy.r_arm.goto_matrix(C)reachy.r_arm.goto_matrix(D)# put the joints back to compliant mode# use turn_off_smoothly to prevent the arm from falling hardreachy.r_arm.turn_off()The result should look like this:
Your browser does not support the video element.
`}),e.add({id:77,href:"/sdk/first-moves/intro/",title:"1. Start with Reachy 2",description:"Quick overview of how to use the robot once connected.",content:`Enable teleop cameras for the SDK #SR camera #The SR camera is unplugged by default.
If you want to use it, plug the SR camera on the robot\u0026rsquo;s computer remaining USB port (2).
Make sure to unplug it if you want to use the teleoperation.
Teleop cameras #The teleop cameras are shared between the teleop service and the SDK server, and can only be used by one at the same time.
In order to be able to use the teleop cameras with the SDK:
Go to the dashboard Stop webrtc service in the services tab Be ready to move #1. Connect to the robot #If you followed the instructions from \u0026ldquo;Connect to Reachy 2\u0026rdquo;, you know how to get Reachy\u0026rsquo;s IP address and how to connect to the robot with the command:
from reachy2_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IP2. Turn on motors #When starting, your robot is in compliant mode, which means you can move its parts by manipulating manually the robot. In this mode, the robot won\u0026rsquo;t respond to any command you send to it.
At each use, you will have to turn on your robot\u0026rsquo;s motors doing:
reachy.turn_on()At the end of your session or program, switch off the motors to send them back to compliant mode doing:
reachy.turn_off()This will act on all parts of your robot, including the mobile base.
If you want to turn on or off a single part, access directly the relevant part and turn it on or off, for example for the left arm:
reachy.l_arm.turn_on()reachy.l_arm.turn_off()All parts are detailed below in ReachySDK attributes.
At any time, you can check the state of your robot using the is_on() or is_off() method. Note that it will return True only if all parts are in the requested state. This means both methods can return False if the right arm is on but not the left one for example.
# Turn on all partsreachy.turn_on()# Check robot statereachy.is_on()\u0026gt;\u0026gt;\u0026gt; Truereachy.is_off()\u0026gt;\u0026gt;\u0026gt; False# Turn off only the left armreachy.l_arm.turn_off()# Check robot statereachy.is_on() # reachy is not on, as left arm is off\u0026gt;\u0026gt;\u0026gt; Falsereachy.is_off() # but reachy is not fully off neither\u0026gt;\u0026gt;\u0026gt; False# Check parts statereachy.r_arm.is_on() # right arm is still on\u0026gt;\u0026gt;\u0026gt; Truereachy.l_arm.is_off() # left arm is off\u0026gt;\u0026gt;\u0026gt; True3. Start from a standard position (optional) #2 standard positions are accessible and can be called easily to setup your starting position:
the zero pose, with all joints set at 0 degree the elbow_90 pose, with the elbow pitch set at -90 degrees and all other joints at 0 degree To start at the zero position, use the set_pose() function:
reachy.set_pose('zero')By default, this movement is made in 2 seconds. You can choose to specify a custom duration. For example, to reach the elbow_90 pose in 5 seconds:
reachy.set_pose('elbow_90', duration=5)Check connection #At any time, you can check the connection between your SDK and the robot is still open with:
reachy.is_connected()\u0026gt;\u0026gt;\u0026gt; TrueIf the connection has been lost, and the problem has been resolved, you can reconnect to the robot with the connect()method:
reachy.connect()💡 You cannot use this method to connect to another IP address. It will automatically reconnect to the initial instantiated robot. ReachySDK object #The reachy object instanciated from the ReachySDK class above is the root access to get all incoming information from Reachy 2 (joints or cameras) and to control each part of the robot (left/right arm, head, mobile base).
The reachy object has 7 attributes and ?? methods that we will quickly present here, more detailed information are given in the dedicated pages after this one.
💡 Note that you can only instantiate one ReachySDK in a session. Attributes #The reachy attributes detailed give to access to info, parts and sensors of the robot.
List of attributes #reachy.cameras
reachy.head
reachy.info
reachy.joints
reachy.l_arm
reachy.mobile_base
reachy.r_arm
reachy.cameras #Camera object. It is used to recover the last image captured by the left camera and also to control the motorized zoom attached to the camera.
reachy.left_camera\u0026gt;\u0026gt;\u0026gt; \u0026lt;Camera side=\u0026quot;left\u0026quot; resolution=(720, 1280, 3)\u0026gt;reachy.head #Head object. Contains the three joints composing the Orbita actuator along with methods for its kinematics or to control it.
reachy.head\u0026gt;\u0026gt;\u0026gt; \u0026lt;Head joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.info #Camera object. It is used to recover the last image captured by the right camera and also to control the motorized zoom attached to the camera.
reachy.right_camera\u0026gt;\u0026gt;\u0026gt; \u0026lt;Camera side=\u0026quot;right\u0026quot; resolution=(720, 1280, 3)\u0026gt;reachy.joints #Joint object containing every joint of the robot, from its arms to its head and antennas. This is useful when you want to get information, like the position, from all joints at once.
reachy.joints\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_shoulder_pitch\u0026quot; pos=\u0026quot;-0.86\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_shoulder_roll\u0026quot; pos=\u0026quot;-0.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_arm_yaw\u0026quot; pos=\u0026quot;-81.45\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_elbow_pitch\u0026quot; pos=\u0026quot;-51.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_forearm_yaw\u0026quot; pos=\u0026quot;-16.28\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_pitch\u0026quot; pos=\u0026quot;-41.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_roll\u0026quot; pos=\u0026quot;-21.26\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_gripper\u0026quot; pos=\u0026quot;-3.08\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;29.65\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-0.94\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-7.60\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.78\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;-0.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-43.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-37.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;140.32\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;79.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;-21.58\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;-79.71\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;-59.27\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;reachy.l_arm #Arm object containing every joint in the left arm along with its kinematics methods.
reachy.l_arm\u0026gt;\u0026gt;\u0026gt; \u0026lt;Arm side=\u0026quot;left\u0026quot; joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_shoulder_pitch\u0026quot; pos=\u0026quot;-0.86\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_shoulder_roll\u0026quot; pos=\u0026quot;-0.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_arm_yaw\u0026quot; pos=\u0026quot;-81.45\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_elbow_pitch\u0026quot; pos=\u0026quot;-51.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_forearm_yaw\u0026quot; pos=\u0026quot;-16.28\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_pitch\u0026quot; pos=\u0026quot;-41.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_roll\u0026quot; pos=\u0026quot;-21.26\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_gripper\u0026quot; pos=\u0026quot;-3.08\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.mobile_base #Arm object containing every joint in the right arm along with its kinematics methods.
reachy.r_arm\u0026gt;\u0026gt;\u0026gt; \u0026lt;Arm side=\u0026quot;right\u0026quot; joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;29.65\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-0.94\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-7.60\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.78\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;-0.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-43.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-37.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.r_arm #Arm object containing every joint in the right arm along with its kinematics methods.
reachy.r_arm\u0026gt;\u0026gt;\u0026gt; \u0026lt;Arm side=\u0026quot;right\u0026quot; joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;29.65\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-0.94\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-7.60\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.78\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;-0.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-43.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-37.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;Basic methods #The reachy object has ?? methods, 8 of them being basic methods useful to start using the robot. The other methods are related to robot movements, and will be detailed in a more advanced section.
List of basic methods #reachy.connect()
reachy.disconnect()
reachy.is_connected()
reachy.is_off()
reachy.is_on()
reachy.turn_off()
reachy.turn_on()
reachy.set_pose()
reachy.connect() #reachy.disconnect() #reachy.is_connected() #reachy.is_off() #reachy.is_on() #reachy.turn_off() #Method to turn off the whole robot. Turning off the robot means putting all parts of the robot in compliant mode, including the mobile base if there is one. See next section for more information on what the compliant mode is for a motor.
reachy.turn_off()reachy.turn_on() #Method to turn on the whole robot. Turning on the robot means putting all the parts of the robot in stiff mode, including the mobile base if there is one. See next section for more information on what the stiff mode is for a motor.
reachy.turn_on()reachy.set_pose() #`}),e.add({id:78,href:"/sdk/first-moves/head/",title:"5. Control the head",description:"Control the head",content:`Head presentation #Reachy 2\u0026rsquo;s head is mounted on an Orbita3D actuator, referred to as the neck actuator, giving 3 degrees of freedom to control the head orientation.
Note : the antennas are not motorized for the moment
Your browser does not support the video element.
The complete head\u0026rsquo;s specifications are given here.
Before starting to control it, connect to your Reachy and turn it on. As in the other pages:
from reachy2_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.head\u0026gt;\u0026gt;\u0026gt; \u0026lt;Head ??\u0026gt;reachy.head.turn_on() # we turn on only the headYou could of course turn on the whole robot by calling reachy.turn_on() directly.
There are several ways to control the head movements:
using the look_at(), rotate_to() and orient() methods, called directly at the head level. These methods works as move commands described previously. controlling the joints goal positions, namely reachy.head.neck.roll, reachy.head.neck.pitch and reachy.head.neck.yaw. Head moves methods #look_at() #You can use the look_at() function to make the head look at a specific point in space. This point must be given in Reachy 2\u0026rsquo;s coordinate system in meters. The coordinate system is the one we have seen previously:
the X axis corresponds to the foward arrow, the Y axis corresponds to the right to left arrow, the Z axis corresponds to the up arrow. The origin of this coordinate system is located in the upper part of the robot trunk.
If you want Reachy to look forward you can send it the following.
reachy.head.turn_on() # Don't forget to put the hand in stiff modereachy.head.look_at(x=0.5, y=0, z=0.2, duration=1.0)You can use multiple look_at to chain head movements, or even chain them with the rotate_to() and orient() functions described below. As seen in the Understand moves in Reachy 2 section, the commands on the head will be stacked.
Your browser does not support the video element.
Here is the code to reproduce this.
import timelook_right = reachy.head.look_at(x=0.5, y=-0.5, z=0.1, duration=1.0)look_down = reachy.head.look_at(x=0.5, y=0, z=-0.4, duration=1.0)look_left = reachy.head.look_at(x=0.5, y=0.3, z=-0.3, duration=1.0)look_front = reachy.head.look_at(x=0.5, y=0, z=0, duration=1.0)The best way to understand how to use the look_at is to play with it. Picture a position you would like Reachy\u0026rsquo;s head to be in, guess a point which could match for the look_at and check if you got it right!
Another cool thing is that we can combine Reachy\u0026rsquo;s kinematics with the look_at so that Reachy\u0026rsquo;s head follows its hand!
Your browser does not support the video element.
reachy.turn_on('head')x, y, z = reachy.r_arm.forward_kinematics()[:3, -1]reachy.head.look_at(x=x, y=y, z=z, duration=1.0)time.sleep(0.5)while True:x, y, z = reachy.r_arm.forward_kinematics()[:3, -1]reachy.head.look_at(x=x, y=y, z=z, duration=0.1)What the code says is that we compute the forward kinematics of Reachy\u0026rsquo;s right arm, and the x, y, z of Reachy\u0026rsquo;s right end-effector in the Reachy\u0026rsquo;s coordinates system will be the coordinates of the point used by the look_at.
rotate_to() #The rotate_to() function is another way to control the head. You directly control the joint of the neck, giving the roll, pitch and yaw angles in degrees. The rotation is made in the order: roll, pitch, yaw, in the Orbita3D coordinate system.
To make the robot looks a little down:
reachy.head.turn_on() # Don't forget to put the hand in stiff modereachy.head.rotate_to(roll=0, pitch=-10, yaw=0, duration=1.0)orient() #The last method to control the head is the orient() method. You can control the head with a quaternion.
You can use pyquaternion library to create suitable quaternion for this method.
from pyquaternion import Quaternionq = Quaternion(axis=[1, 0, 0], angle=3.14159265)reachy.head.turn_on()reachy.head.orient(q)Joint\u0026rsquo;s goal_position #Read head position #You can read the head orientation in two different ways:
using the get_orientation() method, which returns a quaternion using the get_joints_positions() method, which the neck\u0026rsquo;s roll, pitch and yaw present_position. get_orientation() #q = reachy.head.get_orientation()print(q)\u0026gt;\u0026gt;\u0026gt; ??get_joints_positions() #In case you feel more comfortable using roll, pitch, yaw angles rather than working with quaternions, you can retrieve those values from the neck joints.
reachy.head.rotate_to(20, 30, -10)time.sleep(2)reachy.head.get_joints_positions()\u0026gt;\u0026gt;\u0026gt; [20, 30, -10] # roll=20, pitch=30, yaw=-10Be careful that contrary to the quaternion that offers a unique representation of a rotation, it is not the case of the euler angles. Several angles combination can lead to the same orientation in space. For example:
reachy.head.rotate_to(70, -100, 80) # roll=70, pitch=-100, yaw=80time.sleep(2)reachy.head.get_joints_positions()\u0026gt;\u0026gt;\u0026gt; [-110, -80, -100] # roll=-110, pitch=-80, yaw=-100The values are different, nevertheless it is the same final orientation. You can convince yourself doing:
reachy.head.rotate_to(-110, -80, -100)The head won\u0026rsquo;t move.
`}),e.add({id:79,href:"/sdk/first-moves/cameras/",title:"6. Get images from cameras",description:"How to get the images from Reachy 2's cameras.",content:`This section assumes that you went through the Hello World so that you know how to connect to the robot.
Reachy 2 has 2 types of camera:
the teleop cameras, with a right and left cameras, located in Reachy 2\u0026rsquo;s head and used for the teleoperation the SR camera, which is a depth camera, located in Reachy 2\u0026rsquo;s torso and mainly useful for manipulation tasks Each camera can be accessed separately through reachy.cameras. They both have a right and left view, with the left and right sides considered from Reachy point of view. To be able to specify the view you want to get a frame from, you will need to import CameraView:
from reachy2_sdk.media.camera import CameraViewEnable teleop cameras for the SDK #SR camera #The SR camera is unplugged by default.
If you want to use it, plug the SR camera on the robot\u0026rsquo;s computer remaining USB port (2).
Make sure to unplug it if you want to use the teleoperation.
Teleop cameras #The teleop cameras are shared between the teleop service and the SDK server, and can only be used by one at the same time.
In order to be able to use the teleop cameras with the SDK:
Go to the dashboard Stop webrtc service in the services tab Get images #First, connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.cameras\u0026gt;\u0026gt;\u0026gt; ??The list of initialized cameras should contain both the teleop and SR camera.
For each camera, namely the teleop and the SR ones, you must call the capture()function each time you want to get an image. This captures an image from both view of the given camera at the same time. You can then access one of the image with the get_frame() method.
Teleop camera #To get both views of the robot teleop cameras:
from reachy2_sdk import ReachySDKfrom reachy2_sdk.media.camera import CameraViewreachy = ReachySDK(host='192.168.0.42')reachy.cameras.teleop.capture()l_frame = reachy.cameras.teleop.get_frame(CameraView.LEFT)r_frame = reachy.cameras.teleop.get_frame(CameraView.RIGHT)Let\u0026rsquo;s display the captured frame with opencv:
import cv2cv2.imshow(\u0026quot;left\u0026quot;, l_frame)cv2.imshow(\u0026quot;right\u0026quot;, r_frame)cv.waitKey(0)cv.destroyAllWindows()SR camera #The SR camera works exactly the same as the teleop camera, but you have more elements captured. In fact, it a RGBD camera, so you have both access to the RGB images and depth information.
RGB images #Getting RGB images from the SR camera looks the same as from the teleop one: after having called capture(), use get_frame() specifying the CameraView you want to get.
from reachy_sdk import ReachySDKfrom reachy2_sdk.media.camera import CameraViewreachy = ReachySDK(host='192.168.0.42')reachy.cameras.SR.capture()l_frame = reachy.cameras.SR.get_frame(CameraView.LEFT)r_frame = reachy.cameras.SR.get_frame(CameraView.RIGHT)Let\u0026rsquo;s display them with opencv:
import cv2cv2.imshow(\u0026quot;left\u0026quot;, l_frame)cv2.imshow(\u0026quot;right\u0026quot;, r_frame)cv.waitKey(0)cv.destroyAllWindows()Depth information #The SR camera is a depth camera, you can then diplay a left or right depth frame using get_depth_frame(), but also the depthmap and the disparity.
You first have to capture all, then you can read the frame and get the information you want:
from reachy_sdk import ReachySDKfrom reachy2_sdk.media.camera import CameraViewreachy = ReachySDK(host='192.168.0.42')reachy.cameras.SR.capture()l_depth_frame = reachy.cameras.SR.get_depth_frame(CameraView.LEFT)r_depth_frame = reachy.cameras.SR.get_depth_frame(CameraView.RIGHT)depth = reachy.cameras.SR.get_depthmap()disparity = reachy.cameras.SR.get_disparity()Let\u0026rsquo;s display them with opencv:
import cv2cv2.imshow(\u0026quot;sr_depthNode_left\u0026quot;, l_depth_frame)cv2.imshow(\u0026quot;sr_depthNode_right\u0026quot;, r_depth_frame)cv2.imshow(\u0026quot;depth\u0026quot;, depth)cv2.imshow(\u0026quot;disparity\u0026quot;, disparity)cv.waitKey(0)cv.destroyAllWindows()Note that when you call capture() on the SR camera, both RGB images and depth information are captured at the same time.
`}),e.add({id:80,href:"/sdk/first-moves/arm/",title:"3. Basic arm control",description:"What are the joints in Reachy's arms, what information are available and how to control them.",content:` Note : Make sure you checked the safety page before controlling the arm.
Arm presentation #Reachy\u0026rsquo;s arm offers 7 degrees of freedom. It also gives access to one joint for the gripper.
The arm is divided as follow:
shoulder, composed of 2 joints (pitch and roll) elbow, composed of 2 joints (yaw and pitch) wrist, composed of 3 joints (roll, pitch and yaw) We refer to the shoulder, elbow and wrist as actuators.
For some actions, such as changing the compliance, is the the lowest level of control you will have.
The arm\u0026rsquo;s mechanical specifications are given here but as a reminder, the arm schematic is given below:
The actuators #Each actuator has a unique name and uid. To access a specific actuator, you can use the attribute under the part you are using. We don\u0026rsquo;t not provide a direct access to all actuators. For the arms, the following actuators are available:
from reachy2_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.r_arm._actuators\u0026gt;\u0026gt;\u0026gt; \u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;27.98\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;Because they are parallel actuators, it often doesn\u0026rsquo;t have sense to control one motor of an actuator without controlling the other motors of the same actuator.
This is why actuators are for several cases the lowest degree of control we give. At the actuator level, you can then:
modify the actuator compliance modify torques modify speed The joints #Each joint has a unique name and uid. To access a specific joint, you can either use reachy.joints which has each joint of the robot as attribute or access it via the actuators it belongs to. For example, to access the right arm shoulder roll : reachy.r_arm.shoulder.roll.
First, connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.r_arm.shoulder.roll\u0026gt;\u0026gt;\u0026gt; \u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;27.98\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;The name and the id are attributes of the returned Joint object.
reachy.r_arm.r_shoulder_pitch.name\u0026gt;\u0026gt;\u0026gt; 'r_shoulder_pitch'reachy.r_arm.r_shoulder_pitch.uid\u0026gt;\u0026gt;\u0026gt; 8Joints in Reachy are abstract elements that do not have a physical element. A joint is controlled by several motors of the actuators. The only thing you can do at joint level is reading the present_position and send goal_position.
present_position #You can get the present position of each joint with this attribute.
reachy.r_arm.r_shoulder_pitch.present_position\u0026gt;\u0026gt;\u0026gt; 22.4present_position is returned in degrees.
goal_position #The goal_position attribute of a joint can be used to set a new joint\u0026rsquo;s target position to make it move. However, we recommend using the goto_joints() method to move the motors which provides better control on the joint\u0026rsquo;s trajectories.
Using goal_position will make the motor move as fast as it can, so be careful when using it.
reachy.r_arm.r_elbow_pitch.goal_position = -90goal_position must be written in degrees.
The gripper #Arm moves methods #goto_joints() #The goto_joints() method takes a seven-elements-long list, with the angles in this order:
r_arm.shoulder.pitch r_arm.shoulder.roll r_arm.elbow.yaw r_arm.elbow.pitch r_arm.wrist.roll r_arm.wrist.pitch r_arm.wrist.yaw Let\u0026rsquo;s see an example of how to use it.
You will use the goto_joints() methods to place the right arm at a right-angled position. First, make sure that the Reachy\u0026rsquo;s right arm is placed on a cleared table and that there will not be obstacles during its movement.
The setup should look like this:
Let\u0026rsquo;s define a list with reachy.r_arm.elbow.pitch at -90 degrees to the set a right-angled position for the right arm:
right_angled_pose = [0, 0, 0, -90, 0, 0, 0]Then send the goto_joints() commands to the right arm: Set the right arm motors in stiff mode.
reachy.r_arm.turn_on() # don't forget to turn the arm onreachy.r_arm.goto_joints(right_angled_pose)You can use the
The result should look like this:
Your browser does not support the video element.
Don\u0026rsquo;t forget to put the right arm\u0026rsquo;s joints back to the compliant mode. Place your hand below the right arm\u0026rsquo;s gripper to prevent the arm from falling hard on the table.
reachy.r_arm.turn_off()To find out whether you have to send positive or negative angles, read next section on the arm kinematics.
goto_matrix() #The goto_matrix() method takes a 4x4 matrix expressing the target pose of Reachy 2\u0026rsquo;s end effector in Reachy 2 coordinate system.
Read next section on Use arm kinematics to better understand the use of the goto_matrix() method.
Gripper control #open() #To open the grippers, call the open() method on the wanted gripper.
It will open it entirely:
reachy.r_arm.gripper.open()close() #To close the grippers, call the close() method on the wanted gripper.
It will close the gripper with the appropriate value, which means it will be entirely closed if there is no object to grasp, or set a suitable value if an object has been detected in the gripper during the closing:
reachy.r_arm.gripper.close()opening #The opening value corresponds to a percentage of opening, which means:
0 is close 100 is open You can read the opening of the gripper through the opening attribute:
reachy.r_arm.gripper.opening\u0026gt;\u0026gt;\u0026gt; 20 # almost closedYou can also control the opening of the gripper, using the set_opening() method.
Send your custom opening value, still between 0 and 100, to the gripper with:
reachy.r_arm.gripper.set_opening(50) # half-openedNote that there is an smart gripper control that will avoid the gripper from reaching the opening position if an object has been detected while closing the gripper.
Read arm position #get_joints_position() #You can retrieve the values from each arm joints using the get_joints_position() method.
This method returns a seven-elements-long list, with the angles in this order:
r_arm.shoulder.pitch r_arm.shoulder.roll r_arm.elbow.yaw r_arm.elbow.pitch r_arm.wrist.roll r_arm.wrist.pitch r_arm.wrist.yaw Angles are returned in degrees by default.
reachy.l_arm.rotate_to(20, 30, -10)reachy.head.get_joints_position()\u0026gt;\u0026gt;\u0026gt; [7, 10, 4, -50, 4, 5, 7]# r_arm.shoulder.pitch=7, # r_arm.shoulder.roll=10, # r_arm.elbow.yaw=4,# r_arm.elbow.pitch=-50,# r_arm.wrist.roll=4,# r_arm.wrist.pitch=5,# r_arm.wrist.yaw=7,End effector position #You can get the end effector position of Reachy 2 in Reachy 2 coordinate system using forward kinematics.
Call:
reachy.l_arm.forward_kinematics()to get the position of the left gripper in cartesian space.
Read next section on Use arm kinematics to better understand the use of the forward_kinematics() method.
`}),e.add({id:81,href:"/sdk/first-moves/",title:"First Moves",description:"Basic steps to get started with the SDK. Learn how to control each part of Reachy.",content:""}),e.add({id:82,href:"/sdk/development/",title:"Developing with Python SDK",description:"Use Reachy 2 Python SDK.",content:""}),e.add({id:83,href:"/sdk/appendix/support/",title:"Support",description:"Support.",content:`Discord #Join our Discord if you have any questions, maybe someone has already asked the same question or other people could benefit from the answer!
👉 Any questions relative to your development with Reachy?Join the Pollen Community on Discord Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:84,href:"/sdk/appendix/apis/",title:"APIs",description:"Reachy SDK APIs documentation.",content:`The full APIs generated by Sphinx is available at https://pollen-robotics.github.io/reachy-sdk/.
`}),e.add({id:85,href:"/sdk/appendix/",title:"Appendix",description:"Check Reachy SDK API and get support while using the Python SDK.",content:""}),e.add({id:86,href:"/dashboard/introduction/introduction/",title:"What is the dashboard?",description:`We developed Reachy\u0026rsquo;s dashboard to give you an overview of the state of your Reachy (which motors are detected, what services are running, what are the motors temperatures\u0026hellip;) as well as giving you the possiblity to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
What it provides?
Easy setup when you just received your Reachy Reachy will emit its own wifi network Reachy-AP to which you will be able to connect.`,content:`We developed Reachy\u0026rsquo;s dashboard to give you an overview of the state of your Reachy (which motors are detected, what services are running, what are the motors temperatures\u0026hellip;) as well as giving you the possiblity to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
What it provides?
Easy setup when you just received your Reachy Reachy will emit its own wifi network Reachy-AP to which you will be able to connect. From this you can easily connect Reachy to your wifi network and get started with the robot. No need to plug a computer screen, keyboard and mouse to the robot.
First debug step without having to open a terminal If you are not able to connect to Reachy using its Python SDK, it probably means that something went wrong when Reachy\u0026rsquo;s software started. Whether it is because one of Reachy\u0026rsquo;s cable is disconnected or because Reachy\u0026rsquo;s motors has not been turned on, the dashboard will try to tell you what is going on with Reachy without having to type any code. If the problem is not as simple, you also have access to Reachy\u0026rsquo;s services logs to get more information on the problem your robot is encountering.
Easy access to basic information from the robot Monitor motor positions and temperatures, change motors compliance or activate Reachy\u0026rsquo;s fans in one click.
Manage network connection Handle wifi network connection, manage Reachy\u0026rsquo;s hotspot to connect to the robot even when there is no Internet available.
And much more! Because the dashboard is open source like Reachy\u0026rsquo;s hardware and software, you can customize the dashboard and create your own features!
Access the dashboard #From the robot:
Access the dashboard at 127.0.0.1:3972 from any web browser.
From any other device (computer, phone, tablet, \u0026hellip;) on the same network as the robot:
Access the dashboard at \u0026lt;robot-ip\u0026gt;:3972 from any web browser.
Features Overview #The dashboard is composed of five pages:
Debug: indicates if a cable was disconnected or if Reachy\u0026rsquo;s motors were off when Reachy booted, Dashboard: displays the present position and temperature of each joint, allows you to control Reachy\u0026rsquo;s fans and the joints compliance, Services: lets you check which services are running in your robot. You can restart, stop each service and access their logs easily, Wifi: lets you manage Reachy\u0026rsquo;s wireless connection. You can connect your robot to a new wifi network or control its hotspot. On each page, the configuration of the robot will also be displayed (e.g. whether your robot is a full kit, starter kit, \u0026hellip;)
More information is available for each page in the content section.
`}),e.add({id:87,href:"/dashboard/introduction/first-connection/",title:"First connection",description:`When you receive your Reachy, it can be quite confusing at first to get your hands on, that is where the dashboard comes handy.
1. Find Reachy 2\u0026rsquo;s IP address #After you connected the robot to the network, it should have an IP address. You can find it on the LCD screen in the robot\u0026rsquo;s torso.
In case the screen does not display the IP address, follow the instructions of Find Reachy 2\u0026rsquo;s IP.`,content:`When you receive your Reachy, it can be quite confusing at first to get your hands on, that is where the dashboard comes handy.
1. Find Reachy 2\u0026rsquo;s IP address #After you connected the robot to the network, it should have an IP address. You can find it on the LCD screen in the robot\u0026rsquo;s torso.
In case the screen does not display the IP address, follow the instructions of Find Reachy 2\u0026rsquo;s IP.
2. Connect from the navigator #From your computer, on the same network, open a navigator and go to:
http://\u0026lt;IP.address\u0026gt;:8000/
For example, if the screen indicates 192.168.1.42, connect to http://192.168.1.42:8000/
`}),e.add({id:88,href:"/dashboard/content/updates/",title:"Updates",description:"Dashboard page to update Reachy 2 core software.",content:" "}),e.add({id:89,href:"/dashboard/content/dashboard/",title:"Reachy control",description:"Monitor Reachy from Reachy control dashboard page. Send compliance and goal positions commands, and read errors.",content:`The Reachy Control page is a monitoring page where you can both:
read errors from the robot send high level commands, such as goal positions and compliance. Try to turn on or off parts of the robot, or the whole robot.
You can also send commands to make the part moves. Give joints goal positions, express ** in degrees** in Reachy 2 coordinate system.
Have a look to the Arms kinematics page to know the sign of the angles to send to the joints.
Enter the value you want to send, then click Go to to reach the position.
`}),e.add({id:90,href:"/dashboard/content/visualization/",title:"Visualization tools",description:"Dashboard page to access visualization tools for the robot (Foxglove and VNC).",content:`Foxglove #??
VNC #??
`}),e.add({id:91,href:"/dashboard/content/services/",title:"Services",description:"Dashboard page to control Reachy's services.",content:`The page services is dedicated to the services setup for Reachy. Working with services has the advantage of having Reachy\u0026rsquo;s code running automatically at boot whithout needing to open a terminal and start it yourself. However using the services can make debugging the robot more difficult because the code running for Reachy is \u0026ldquo;hidden\u0026rdquo;, that is why we made this page.
Having this page is useful when something is going wrong with Reachy. For example, if you went on the debug page and you were told that a motor was disconnected, you can reconnect the motor indicated and restart Reachy\u0026rsquo;s code using the button restart of reachy_sdk_server.service. This way you won\u0026rsquo;t have to reboot Reachy\u0026rsquo;s computer just to restart its code. Or if you forgot to turn on Reachy\u0026rsquo;s motors before booting, you can just restart the service.
Content #In this page, one card will be created per Reachy\u0026rsquo;s service. Typically the page will looks like the following:
For each service, it will be indicated whether the service is currently running or not and three buttons will be available:
Restart: restarts the service, Stop: stops the service, Show logs: displays the logs of the service. Having the logs is useful for debugging, you will be able to see the error messages on what is causing the problem as if you were launching Reachy\u0026rsquo;s code in a terminal. Notes #💡 Only services whose names start with reachy_ and in \u0026ndash;user mode will be displayed on the page.
For more information on how to handle the Reachy\u0026rsquo;s services and what they are used for, check the services page.
`}),e.add({id:92,href:"/dashboard/content/network/",title:"Network",description:"Dashboard page to manage Reachy's network connection.",content:`The wifi page of the dashboard lets you handle the network connection of the robot and typically looks like the following:
There are four main elements on this page:
Connection card: this card will display whether Reachy is connected to the Internet with an ethernet cable or a wifi network (in which case it will tell you which wifi network) or if it is using its hotspot,
Wifi adder card: this card will help you connect Reachy to a wifi network. The dropdown will list each wifi network detected and you will be able to connect to the one you want by entering your wifi password in the corresponding box,
Reachy\u0026rsquo;s IP address card: this card will display Reachy\u0026rsquo;s IP address. If Reachy\u0026rsquo;s hotspot is activated, its IP address is fixed and is 10.42.0.1,
Hotspot toggle: this will allow you to turn on/off Reachy\u0026rsquo;s hotspot.
Reachy\u0026rsquo;s Hotspot #Reachy is able to emit its own wifi when needed. By default the hotspot is turned on when the dashboard is started and no wifi networks are known. This is the case when you first receive your Reachy for example. Having a hotspot is useful because it gives you the possibility to connect remotely to Reachy even when no wifi network is available.
When the hotspot is on, Reachy will emit its wifi under the network name Reachy-AP. The password to connect to it is the same as the network name, Reachy-AP (mind the capital letter, the password is case sensitive).
When the hotspot is on, Reachy always has the same IP address on the network: 10.42.0.1.
Changing wifi network #You can connect Reachy to a wifi network using the Wifi adder card.
When you change the wifi network, the following message will appear:
If you try to change the wifi network and fail to enter the correct password, Reachy will switch to hotspot mode and you will have to try again to update the wifi network by connecting to Reachy-AP.
Notes #💡 If you installed the dashboard yourself, you will need to forget previsouly known wireless networks on Reachy and only use the dashboard when handling wireless networks.
`}),e.add({id:93,href:"/dashboard/introduction/",title:"Introduction",description:"Introduction to Reachy's dashboard.",content:""}),e.add({id:94,href:"/dashboard/content/",title:"Content",description:"What you can find in Reachy's dashboard.",content:""}),e.add({id:95,href:"/dashboard/",title:"Dashboard",description:"Use the dashboard to check Reachy's status, debug Reachy's issues and start applications.",content:""}),e.add({id:96,href:"/docs/update/",title:"Update Reachy",description:"Learn how to update Reachy's software.",content:""}),e.add({id:97,href:"/docs/update/update/",title:"Update Reachy 2 software",description:"Update Reachy",content:`Use the dashboard #The update of the robot can be entirely done with the dashboard.
From the Updates tab, check if updates are available:
Only advanced update management is working so far
Advanced update management #From the dashboard Update page, click on Advanced udpate management:
You can directly access the advanced update dashboard from http://\u0026lt;IP.address\u0026gt;:5000/
Fetch updates #Click Fetch Updates to check if there is any available update on one of the robot\u0026rsquo;s services.
Once this is done, you can browse between the 5 services to see if a more recent version is available.
For example, an update is available for reachy2-dashboard here: Install update #Select the version you want to download for the upgrade, and click on Pull Container.
Wait for the message \u0026ldquo;service.name Pulled\u0026rdquo; to appear in the window.
When this is done, click on Generate.
Wait for the confirmation message to appear.
Activate the update #Finish the update installation by clicking on:
Enable, to activate by default the updated service Stop, to stop the current outdated service running Start, to launch the updated service `}),e.add({id:98,href:"/docs/simulation/",title:"Simluation installation",description:"Simulation installation process.",content:""}),e.add({id:99,href:"/docs/advanced/",title:"Advanced usage",description:"Advanced usage with Reachy 2.",content:""}),e.add({id:100,href:"/docs/getting-started/",title:"Getting Started",description:"On first start.",content:""}),e.add({id:101,href:"/sdk/",title:"Docs",description:"Discover the Python SDK for Reachy and its mobile base.",content:""}),e.add({id:102,href:"/docs/",title:"Docs",description:"Learn how to install and get started with Reachy.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()